% \section{Modelagem com inclusão de instrumento e gênero}
\subsection{Base restrita a faixas inéditas} 

Uma característica particular das sessões do Indaband é a capacidade de criar
uma sessão a partir de outra já existente, modificá-la, adicionar novas
gravações e publicá-la como uma nova iteração a partir da funcionalidade de
\textit{fork}.

Essa funcionalidade é muito utilizada pelos usuários. A tabela \ref{tab_sessoes}
mostra que 76\% das faixas criadas são geradas via \textit{fork},
independentemente se foram publicadas ou não. Dessa forma, usuários distintos
podem contribuir para uma mesma sessão em momentos distintos, ou um usuário pode
contribuir para uma mesma sessão de outro usuário que era desconhecido até
então.

Uma vez que o objetivo é recomendar usuários prováveis de contribuir gravando
uma faixa inédita para uma determinada sessão, é razoável gerar um cenário em
que o recomendador seja treinado e avaliado estritamente para prever a próxima
faixa inédita gravada.

As abordagens \textit{next-item} e \textit{remaining-items} são as mais
utilizadas nos comparativos publicados porque aproveitam todos os itens de cada
sessão para o treinamento ou para a avaliação. No caso de uma aplicação em que
haja redundância entre as sessões, em que usuários possam salvar, repetir e
compartilhar sessões entre si, essas abordagens acabam por facilitar o trabalho
do recomendador, uma vez que cada iteração a mais no processo de treinamento
significa uma nova oportunidade para minimizar o erro do modelo. O mesmo vale
para a avaliação, em que identificar faixas \textit{forkadas} seria em tese uma
tarefa mais fácil. O cenário mais desafiador é aquele em que o item a ser
avaliado é necessariamente um item inédito no contexto daquela sessão.

Em contraponto, a abordagem \textit{last-item} é a que mais se aproxima do
cenário mencionado, uma vez que mantém inalterada a sequência de itens das
sessões. O que muda é a forma de avaliação, que passa a considerar apenas o
último item da sequência como o item a ser previsto, sem que os demais itens
anteriores sejam avaliados, minimizando a influência de itens \textit{forkados}
na avaliação.

Com essa finalidade, a base de treinamento do presente trabalho é filtrada:
Nesse último experimento, constam apenas sessões em que o último item da
sequência é a adição de uma faixa inédita na plataforma. Essa identificação é feita a partir
de um metadado disponível, informando se a faixa foi gerada por um \textit{fork}
ou foi criada, seja por gravação, por importação de uma faixa ou por separação
de fontes.

Para essa abordagem, é utilizado o avaliador \textit{last-item}. Esse avaliador
considera apenas o último item da sequência como o item a ser previsto, sem que
os demais itens advindos de \textit{fork} sejam recomendados.

\begin{table}[htbp]
  \small
  \centering
    \begin{tabular}{|l|l|l|l|l|l|l|l|}
      \hline
      Modelo & HR@5 & HR@10 & MRR@5 & MRR@10 & Cov@10 & Pop@10  \\
      \hline
      GNN & \textbf{0,551} & \textbf{0,625} & \textbf{0,437} & \textbf{0,446} & 0,660 & 0,202  \\
      \hline
      $\text{STAMP}_1$ & 0,519 & 0,584 & 0,377 & 0,386 & 0,610 & 0,217 \\
      \hline
      sknn2 & 0,518 & 0,647 & 0,213 & 0,230 & 0,643 & 0,169 \\
      \hline
      sknn1 & 0,515 & 0,642 & 0,209 & 0,226 & 0,592 & 0,197 \\
      \hline
      ct & 0,509 & 0,579 & 0,390 & 0,399  & 0,477 & 0,349 \\
      \hline
      $\text{STAMP}_2$ & 0,506 & 0,590 & 0,366 & 0,377 & 0,609 & 0,201 \\
      \hline
      $\text{NextItNet}_2$ & 0,465 & 0,563 & 0,341 & 0,354 & 0,566 & 0,249 \\
      \hline
      $\text{STAN}_2$ & 0,464 & 0,596 & 0,178 & 0,196 & 0,547 & 0,179 \\
      \hline
      $\text{STAN}_1$ & 0,451 & 0,572 & 0,186 & 0,202 & 0,529 & 0,177 \\
      \hline
      $\text{NextItNet}_1$ & 0,449 & 0,536 & 0,337 & 0,349 & 0,525 & 0,257\\
      \hline
      vsknn1 & 0,447 & 0,580 & 0,1193 & 0,211 & 0,544 & 0,208 \\
      \hline
      $\text{VSTAN}_1$ & 0,441 & 0,580 & 0,180 & 0,198 & 0,507 & 0,221 \\
      \hline
      $\text{SMF}_2$ & 0,439 & 0,553 & 0,291 & 0,306 & 0,306 & 0,240 \\
      \hline
      $\text{SMF}_1$ & 0,431 & 0,530 & 0,298 & 0,311 & 0,240 & 0,257 \\
      \hline
      vsknn2 & 0,427 & 0,564 & 0,172 & 0,190 & 0,618 & 0,163 \\
      \hline
      $\text{SR}_2$ & 0,423 & 0,534 & 0,277 & 0,291 & 0,471 & 0,238 \\
     \hline
      $\text{VSTAN}_2$ & 0,418 & 0,546 & 0,171 & 0,189 & 0,588 & 0,142 \\
      \hline
      $\text{SR}_1$ & 0,410 & 0,512 & 0,279 & 0,292 & 0,445 & 0,259 \\
      \hline
      ar & 0,395 & 0,498 & 0,248 & 0,262 & 0,454 & 0,265 \\
      \hline 
      $\text{NARM}_1$ & 0,361 & 0,455 & 0,229 & 0,241 & 0,658 & 0,199 \\
      \hline
      $\text{NARM}_2$ & 0,324 & 0,440 & 0,211 & 0,226 & 0,665 & 0,188 \\
      \hline
      FOSSIL & 0,287 & 0,420 & 0,137 & 0,154 & 0,776 & 0,249 \\
      \hline
      FPMC & 0,281 & 0,419 & 0,124 & 0,143 & 0,764 & 0,241 \\
      \hline
      FISM & 0,275 & 0,434 & 0,120 & 0,141 & 0,749 & 0,240 \\
      \hline
      BPRMF & 0,271 & 0,407 & 0,122 & 0,141 & 0,744 & 0,250 \\
      \hline
      CSRM & 0,264 & 0,343 & 0,158 & 0,168 & 0,596 & 0,137  \\ 
      \hline
      $\text{GRU4Rec}_2$ & 0,208 & 0,278 & 0,130 & 0,139 & 0,873 & \textbf{0,030}  \\
      \hline
      $\text{GRU4Rec}_1$ & 0,195 & 0,271 & 0,123 & 0,134 & \textbf{0,858} & 0,040  \\
      \hline
      rpop & 0,165 & 0,225 & 0,106 & 0,113 & 0,009 & 0,319 \\
      \hline
      pop & 0,127 & 0,242 & 0,083 & 0,098 & 0,006 & 0,530 \\
      \hline
      spop & 0,125 & 0,219 & 0,059 & 0,071 & 0,299 & 0,471 \\
      \hline
      random & 0,003 & 0,005 & 0,001 & 0,001 & 1,000 & 0,014 \\
      \hline
      \end{tabular}
      \label{tab:results_last_item_final}
    \caption{Resultado dos modelos \textit{session-based} na abordagem
    \textit{single item}, avaliando o último item da sessão. Modelos ordenados por HR@5. }
  \end{table}

  A tabela \ref{tab:results_last_item_final} mostra os resultados obtidos pela
  abordagem \textit{last-item}. As métricas obtiveram valores na mesma faixa da
  abordagem \textit{next-item}, demonstrando que, por mais que a avaliação e o
  treinamento seja reservados apenas ao último item da sequência, os modelos
  mantém desempenho equivalente.
  
  Novamente, o modelo GNN obteve os melhores resultados. Modelos
  mais simples, como o skNN e a árvore de contexto também obtiveram bons
  resultados.




