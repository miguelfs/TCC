\section{Recomendações Não-Personalizadas}
Recomendações não-personalizadas oferecem de forma homogênea conteúdo
potencialmente relevante a todos os usuários a partir da opinião agregada, sem
considerar preferências individuais \cite{poriya2014non}. Sua vantagem é a
abordagem intuitiva e de fácil implementação. No entanto, a preferência
individual de cada usuário é posta em detrimento da preferência coletiva.

Uma recomendação não-personalizada típica é a de itens mais populares, podendo
ser modelada de formas distintas. Por exemplo, os modelos \textit{MostPop},
\textit{RecentPop} e \textit{DecayPop}~\cite{ji2020re, jing2023capturing}
representam, respectivamente, os itens com maior popularidade global, maior
popularidade da última semana e mais populares das últimas seis semanas com
decaimento exponencial.

Uma característica da recomendação por popularidade é a distribuição em
cauda-longa da frequência de recomendações: uma pequena parcela dos itens
concentra a maior parte das avaliações. Como consequência, essa forma de
recomendação possui diversidade mínima~\cite{aggarwal2016recommender}. A
diversidade implica que, em uma lista de recomendações, cada recomendação
individual seja o mais distinta possível das demais. Esse aspecto evita que,
caso o usuário não se interesse por determinado item, ele não se interesse por
nenhum dos demais. Uma maior diversidade de um sistema de recomendação implica
em uma maior cobertura desse mesmo sistema~\cite{aggarwal2016recommender}.

Uma abordagem de recomendação não-personalizada com diversidade máxima é a
recomendação aleatória. Possui pouco uso prático ao usuário final, exceto em
situações em que deseja-se receber recomendações inéditas independentes da
popularidade. Apesar disso, é uma forma de recomendação útil em base de
comparações de desempenho de outros modelos, uma vez que expõe um valor mínimo
de taxa de acerto a ser superada. Um recomendador útil deve superar a taxa de
acerto de um recomendador aleatório.

\section{Filtragem Colaborativa Baseada em Vizinhança} A filtragem
colaborativa baseada em vizinhança~\cite{aggarwal2016recommender} é um método de aprendizado não-supervisionado
que divide-se em duas categorias:
\begin{enumerate}
    \item baseada em usuário, em
que as preferências similares entre usuários são utilizadas para recomendar
itens entre si;
    \item baseada em itens, em que a similaridade de itens selecionados
por um mesmo usuário com os demais disponíveis é utilizada para recomendar um
item inédito a ele.
\end{enumerate}

\begin{figure}[h!]
    \centering
    \begin{tikzpicture}
        \matrix (mat) [matrix of nodes,
                       nodes in empty cells,
                       nodes={minimum width=1.5cm,
                              minimum height=1.5cm,
                              outer sep=0pt,
                              anchor=center,
                              text centered,
                              draw,
                              fill=gray!20},
                       row sep=-\pgflinewidth,
                       column sep=-\pgflinewidth]
        {
        1 & 5 & & 3 & 4 \\    
        1 & 5 & & 3 & 4 \\
        2 & & 4 & & 2 \\
        3 & 3 & & 5 & \\
        };
        % Row labels
        \foreach \i in {1, 2,3,4} {
            \node[left=0.5cm of mat-\i-1.west] {Usuário \i};
        }
        % Column labels
        \foreach \i in {1,2,3,4,5} {
            \node[above=0.5cm of mat-1-\i.north] {Item \i};
        }
    \end{tikzpicture}
    \caption{Matriz de avaliações para filtragem colaborativa, $m=4$ e $n=5$.}
    \label{fig:ratings_matrix}
\end{figure}

\symbl{$R_{m \times n}$}{Matriz de avaliações com $m$ usuários e $n$ itens}
\symbl{$R_{uj}$}{Avaliação do usuário $u$ ao item $j$}
Para viabilizar a filtragem colaborativa, utiliza-se a matriz de avaliações
$R_{m \times n}$, a exemplo da FIGURA \ref{fig:ratings_matrix}: $m$ é a quantidade de usuários, $n$ é a quantidade de
itens e $R_{uj}$ é a avaliação dada pelo usuário $u$ ao item $j$, quando
preenchida. Assume-se que a matriz $R_{m \times n}$ é esparsa, com poucos
valores preenchidos.

Em vez de preencher todos os valores faltantes de $R_{m \times n}$,
determinam-se os $k$ itens mais relevantes para um usuário. Por questão de
facilidade de preenchimento, as avaliações em $R_{m \times n}$ costumam ser
valores discretos dentro de uma escala limitada ou valores binários.

A prática mais comum é optar por alguma medida de similaridade entre vetores em
um espaço de usuários ou itens, como o produto escalar normalizado, o cosseno
entre dois vetores ou o coeficiente de correlação de Pearson. Tanto os vetores
de usuário quanto os vetores de item podem utilizar Pearson ou cosseno.

\subsubsection{Similaridade de Usuário}
O coeficiente de correlação de Pearson é a razão da covariância com o produto
do desvio padrão de duas variáveis aleatórias~\cite{aggarwal2016recommender}.

\symbl{$r$}{coeficiente de correlação de Pearson}
\symbl{$\bar{x}$}{média de um vetor $x$}
Para um conjunto de amostras ou de observações, o coeficiente de
correlação $r$ de Pearson entre dois vetores $x$ e $y$ de tamanho $N$, cujas
médias são $\bar{x}$ e $\bar{y}$, é dado por:

\begin{equation}    
    r(x,y) = \frac{\sum_{i=1}^{N}(x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\sum_{i=1}^{N}(x_i - \bar{x})^2} \sqrt{\sum_{i=1}^{N}(y_i - \bar{y})^2}}, \quad r \in \mathbb{R}, -1 \leq r \leq 1.
\end{equation}
\symbl{$\mathbb{R}$}{conjunto dos números reais}

O coeficiente de correlação entre dois vetores de usuários $u$ e $v$ é calculado
a partir dos itens avaliados em comum por ambos os usuários. Sendo $I_u$ e $I_v$
os conjuntos de itens avaliados pelos usuários $u$ e $v$,
o tamanho dos vetores $x$ e $y$ é dado por:
\symbl{$I_u$}{conjunto de itens avaliados pelo usuário $u$}
\symbl{$\cap$}{operador de interseção}
\begin{equation}
    N = |I_u \cap I_v|.
\end{equation}

Seja $P_u (j)$ o subconjunto dos usuários de maior similaridade com o usuário
$u$ que necessariamente avaliaram o item $j$. \symbl{$\hat{R}_{uj}$}{Avaliação predita do usuário $u$ ao item $j$}
A predição de avaliação
$\hat{R}_{uj}$ do usuário $u$ a um único item $j$ é calculada a partir de uma
normalização das avaliações dos demais usuários sobre esse mesmo item,
considerando a similaridade deles com o usuário $u$ em questão:

\begin{align}
    \label{eq:predicao}
\hat{R}_{uj} &= \bar{u} + \frac{\sum_{v \in Pu(j)} r(u,v) \cdot s_{vj}}{\sum_{v \in Pu(j)} |r(u,v)|} \\
s_{vj} &= R_{vj} - \bar{v} \label{eq:centered_mean}
\end{align}

As variações da função de predição em \ref{eq:predicao} utilizam o desvio padrão
para realizar o ajuste em vez das médias $\bar{u}$ e $\bar{v}$, amplificam o
peso $r(u,v)$ ao elevá-lo por uma potência maior que 1 e descontam o peso quando
dois usuários tem poucos itens em comum~\cite{aggarwal2016recommender}.

A equação \ref{eq:centered_mean} ajusta tanto as avaliações de um usuário que
avalia todos seus itens de forma muito rigorosa com notas baixas, quanto de
outro usuário muito satisfeito que avalie todos seus itens com notas altas. Esse
ajuste desconta a média das avaliações de determinado usuário, retornando uma
avaliação centrada na média dele.

A abordagem apresentada é considerada um problema de regressão, dado que o objetivo é prever
o valor de uma variável contínua a partir de outras variáveis. Apesar disso, é
possível implementar um classificador a partir da função de predição descrita,
determinando limiares para as variáveis contínuas.

\subsubsection{Similaridade de Item}

O cosseno do ângulo entre dois vetores $x$ e $y$ é obtido a partir de seu
produto interno:

\symbl{cos(x,y)}{cosseno do ângulo entre os vetores $x$ e $y$}
\symbl{$\|x\|$}{norma do vetor $x$}
\begin{equation}
    \cos(x,y) = \frac{x \cdot y}{\|x\| \|y\|}, -1 \leq \cos \leq 1.
\end{equation}

Para utilizar o cosseno como medida de similaridade entre itens, é necessário
primeiramente ajustar as avaliações de cada item pela sua
média~\cite{aggarwal2016recommender}. O processo é análogo ao descrito para a
equação \ref{eq:centered_mean}. A intuição é identificar o quanto determinada
avaliação desvia da média das avaliações de determinado item.

\begin{align}
    s_{ui} &= R_{ui} - \bar{i} \\
    s_{uj} &= R_{uj} - \bar{j} \\
    \cos(s_{ui},s_{uj}) &= \frac{s_{ui} \cdot s_{uj}}{\|s_{ui}\| \|s_{uj}\|}
\end{align}

A similaridade entre dois itens é calculada a partir das avaliações de todos os
usuários que avaliaram os dois itens $i$ e $j$. Nesse caso, o tamanho do vetor é dado por:

\begin{equation}
    N = |U_i \cap U_j|.
\end{equation}

Seja $Q_t (u)$ o subconjunto dos itens de maior similaridade com o item $t$ que
foram avaliados pelo usuário $u$ em particular.

O objetivo é determinar a avaliação predita $\hat{R}_{ut}$ de um item-alvo $t$ para um usuário
$u$. Esse valor é calculado a partir da normalização das avaliações do mesmo
usuário $u$ sobre os itens contidos em $Q_t (u)$:

\begin{equation}
    \hat{R}_{ut} = \frac{\sum_{j \in Q_t(u)} \cos(s_{uj},s_{ut}) \cdot s_{uj}}{\sum_{j \in Q_t(u)} |\cos(s_{uj},s_{ut})|}
\end{equation}

\subsubsection{Pares de Grupos}

Uma otimização para estimar avaliações em tempo real consiste em pares de grupos
pré-calculados~\cite{aggarwal2016recommender}. Esses pares são o conjunto limitado de usuários ou itens com
maior similaridade entre si. Nessa abordagem, a etapa \textit{offline} gera os
pares de grupos, atualizada periodicamente. A etapa \textit{online} estima uma
avaliação a partir dos pares pré-calculados.

Na etapa \textit{offline} do método por similaridade de usuário, determinado
usuário que tenha avaliado $n' \ll n$ itens é associado a um grupo de usuários
de maior similaridade com ele, o que exige complexidade de $O(m \cdot n')$ em
tempo de execução ao perpassar por todos os $m$ usuários em cerca de $n'$ itens
avaliados. A etapa \textit{online} consiste em estimar a avaliação a partir dos
$k$ usuários do grupo, o que exige complexidade de $O(k)$ em tempo de execução,
viabilizando-o para o cálculo de recomendações em tempo real.
 
As principais vantagens dos métodos baseados em vizinhança são sua abordagem
simples, intuitiva e de fácil implementação. A depender do tamanho da base, é
impraticável estimar uma avaliação em tempo real sem o uso de pares de grupos,
em razão da alta complexidade em tempo de execução. Principalmente,
há modelos atuais que são mais precisos, inclusive os baseados em modelos.

\section{Sistemas de Recomendação \textit{Model-based}}
A filtragem colaborativa baseada em modelos é um método de aprendizado em que um
modelo representativo dos dados é necessariamente criado primeiro, com etapas de
treinamento e predição estritamente separadas. Essa característica  não é uma
restrição nos métodos baseados em vizinhança, apesar de ser uma prática que
concede eficiência em sua execução.

As principais vantagens dos métodos baseados em modelos, quando comparados aos de vizinhança, são~\cite{aggarwal2016recommender}:
\begin{itemize}
    \item compressão do modelo, em que seu tamanho é bem menor que o da matriz de avaliações $R_{m \times n}$;
    \item rapidez de treinamento e predição, uma vez que o modelo é mais compacto, sendo necessário perpassar por menos dados.
    % \item evita overfitting    
\end{itemize}

\subsubsection{Fatoração de Matrizes}
A fatoração de matrizes pode ser empregada como alternativa aos métodos baseados
em vizinhança, reduzindo a dimensionalidade do conjunto de dados. Nesse método,
obtém-se vetores de variáveis latentes que representam os usuários e itens de
forma compacta, reduzindo os efeitos associados à esparsidade do conjunto de
dados.

\abbrev{SVD}{\textit{singular value decomposition}}
\abbrev{PCA}{\textit{principal component analysis}}
Métodos tradicionais de álgebra linear podem ser empregados para reduzir a
dimensionalidade de uma matriz de avaliações. Por exemplo, a decomposição em
valores singulares (SVD, do inglês \textit{singular value decomposition}) ou
análise dos componentes principais (PCA, do inglês \textit{principal component
analysis}).

\subsubsection{SVD}
A SVD consiste em decompor uma matriz $A$ de dimensões $m \times n$ em três
matrizes $U$, $\Sigma$ e $V$ da seguinte forma \cite{strang2006linear}:

\symbl{$\mathbf{T}$}{Operador de transposição de matriz}
\begin{equation}
    A = U \Sigma V^{\mathbf{T}}
    \label{eq:SVD}
\end{equation}
A matriz $U$ é ortogonal de dimensões $m \times m$, contendo em suas colunas
os autovetores de $AA^{\mathbf{T}}$. A matriz $V$ é ortogonal de dimensões $n
\times n$, contendo em suas colunas os autovetores de $A^{\mathbf{T}}A$. A
matriz $\Sigma$ é diagonal de dimensões $m \times n$, contendo os  autovalores
de $A^{\mathbf{T}}A$. Os autovalores, ordenados de forma decrescente, indicam
quais autovetores são mais relevantes para representar a matriz $A$.

Uma aproximação em representação compacta para a matriz $A$ consiste em truncar
os autovetores cujos autovalores são mais representativos da matriz $A$. Isto é,
para os $r$ maiores valores singulares. Os demais valores singulares são
substituídos por zero na diagonal de $\tilde{A}$. Dessa forma, o posto da matriz
$\tilde{A}$ é igual a $r$ \cite{brunton2022data}:

\begin{equation}
    A \approx \tilde{A} = \sum_{k=1}^{r}\sigma_k \mathbf{u}_k \mathbf{v}_k^{\mathbf{T}}
\end{equation}

Uma importante propriedade da aproximação pela SVD truncada é a garantia da
minimização do erro quadrático de forma ótima entre a matriz original e a matriz
aproximada, para uma matriz de posto $r$:

\begin{equation} \label{echart_young}
    \min_{\tilde{A} \mid \text{posto}(\tilde{A}) = r } \|A - \tilde{A}\|_F = \sqrt{\sum_{i=r+1}^{n}\sigma_i^2}
\end{equation}
em que $\| \cdot \|_F$ é a norma de Frobenius. A equação \ref{echart_young}
consiste no teorema de Eckart-Young.
\symbl{$\| \cdot \|_F$}{Norma de Frobenius}


É possível formular um sistema de recomendação aplicando a SVD sobre a matriz de
avaliações $R_{m \times n}$. Primeiramente, $R_{m \times n}$ é preenchida nos
valores faltantes segundo a média de cada linha e cada coluna, representando as
avaliações de cada usuário e para cada item, respectivamente. O resultado é a
matriz $R_f$.

A matriz de similaridade $S$ é obtida a partir de $S = R_f^{\mathbf{T} }R_f$.
Note que S é de dimensão $n \times n$, em que $n$ é a quantidade de itens. $S$ é
uma matriz positiva semi-definida, isto é, todos seus autovalores são
não-negativos, seguindo a propriedade:

\begin{equation}
    \mathbf{x}^{\mathbf{T}} S \mathbf{x} \geq 0, \forall \mathbf{x} \neq 0
\end{equation}

 Para obter uma base de autovetores que representam a matriz $S$ de forma
 compacta, utiliza-se a SVD para obter tanto os autovetores quanto os
 autovalores, aproveitando o caso particular em que $S$ é positiva
 semi-definida:

\begin{equation}
    S = P \Lambda P^{\mathbf{T}}
\end{equation}

P é a matriz $n \times n$ de autovetores de $S$ e $\Lambda$ é a matriz diagonal
de autovalores não-negativos de $S$.

Finalmente, a representação compacta almejada consiste na seleção de $P_d$ autovetores com os $d$
maiores autovalores, mais representativos do espaço original, em uma forma compacta.
A matriz compacta de avaliações é dada por $R_{f}P_{d}$, de dimensão $m \times
d$ com $d$ usuários, em vez de $m \times n$ com $n$ usuários, tal como na matriz
de avaliações original.

A partir da matriz $R_{f}P_{d}$, é possível realizar a filtragem colaborativa
baseada em itens e baseada em usuários~\cite{aggarwal2016recommender}, como descrito anteriormente.

\subsubsection{Modelo de Fatores Latentes}
Um caso particular da SVD, denominado modelo de fatores latentes, ganhou
visibilidade com a competição \textit{Netflix Prize}, cujo objetivo era superar
o desempenho do algoritmo de recomendação vigente da empresa na época~\cite{lessons_netflix_prize}.

No caso do modelo de fatores latentes, a matriz de avaliações $R$ é decomposta
da seguinte forma \cite{aggarwal2016recommender}:
\begin{equation}
    R = QP^{\mathbf{T}}
\end{equation}
sendo um caso particular da SVD na equação \ref{eq:SVD} : $R = A$, $Q = U$ e $P = \Sigma V^{\mathbf{T}}$.
Na bibliografia, o componente $Q$ é denominado vetor latente, enquanto que
$P^{\mathbf{T}}$ é denominado fator latente.
% Caso as linhas da matriz $R$
% representem os itens, enquanto que suas colunas representam os usuários, as
% linhas da matriz P representa os usuários e a matriz $Q^{\mathbf{T}}$ representa os itens.

Os valores das matrizes Q e P são obtidos ao minimizar o erro quadrático de uma
função de custo, a partir de um método de otimização como o gradiente
descendente estocástico. Como a matriz de avaliações $R$ é esparsa,
podendo conter poucas avaliações por usuário, é necessário aplicar regularização
para evitar \textit{overfitting}. A regularização em questão consiste em
penalizar valores altos de $P$ e $Q$ quando há poucas avaliações disponíveis:

\begin{align}
    \arg\min_{Q,P} f(Q,P) &= L(Q,P) + \lambda F(Q,P) \\
    \arg\min_{Q,P} f(Q,P) &= \sum_{u,j} (R_{uj} - Q_j P_u^{\mathbf{T}})^2 + \lambda (\sum_u \|Q_u\|^2 + \sum_j \|P_j\|^2)
\end{align}

em que $L(Q,P)$ é a parcela de custo, $F(Q,P)$ é a parcela de penalidade e
$\lambda$ é o parâmetro de regularização. Uma vez obtidas as matrizes $P$ e $Q$,
a predição de avaliação $\hat{R}_{uj}$ do usuário $u$ ao item $j$ é calculada a
partir do produto interno entre o vetor latente e o fator latente representativo
desse par:

\begin{equation} \label{fator_latente}
    \hat{R}_{uj} = \mathbf{q}_j \mathbf{p}_u^{\mathbf{T}}
\end{equation}


\subsubsection{Regras de Associação}
Regras de associação são técnicas para identificação de padrões relacionais
na forma de regras, analisando conjuntos de dados de transações. Os métodos que
utilizam dessa técnica, como o algoritmo Apriori, realizam uma análise exaustiva
por padrões frequentes de conjuntos ou de associação entre itens, tornando-os
adequados para identificar regras preditivas \cite{jannach2011recommender}.

Considere um conjunto de transações $\mathcal{T} = \{T_1, T_2, \dots, T_n\}$ e
um conjunto de itens $I = \{i_1, i_2, \dots, i_m\}$, tal que toda transação seja
um subconjunto de itens, isto é, $T_i \subseteq I$.

Uma regra de associação é uma
implicação da forma $X \Rightarrow Y$, em que $X$ e $Y$ estão contidos em $I$ e
$X \cap Y = \emptyset$ \cite{ordonez2011evaluating}.

Uma modelo de regras de associação
pode ser implementado com a estrutura de dados de dicionário da seguinte forma:

\begin{center}
    \begin{tabular}{c}

\begin{lstlisting}[language=Python]
    {A: {X: 1}, B: {Y: 2}, C: {Z: 3}}
\end{lstlisting}
\end{tabular}
\end{center}
em que A, B e C são subconjuntos de itens antecedentes e X, Y e Z são
subconjuntos de itens consequentes, com uma, duas e três ocorrências,
respectivamente. O dicionário é implementado a partir de uma matriz de ocorrências,
em que cada linha representa uma transação e cada coluna representa um item.

% \begin{table}
%     \begin{center}
%         \begin{tabular}{|c|c|c|c|c|c|}
%             \hline
%             \textbf{Consumidor} & pão & manteiga & leite & presunto & queijo \\
%             \hline
%             João & 1 & 1 & 0 & 0 & 0 \\
%             Maria & 1 & 1 & 1 & 0 & 0 \\
%             Pedro & 0 & 0 & 1 & 1 & 0 \\
%             Roberta & 0 & 1 & 0 & 1 & 1 \\
%             Carol & 0 & 1 & 0 & 0 & 1 \\
%             José & 1 & 1 & 1 & 1 & 1 \\
%             \hline
%         \end{tabular}
%         \label{tab:transactions_transacoes}
%     \end{center}
%     \caption{Tabela de transações de compras de supermercado, utilizada como uma matriz de ocorrências em um modelo de regras de associação.}
%     \end{table}
    

No contexto de sistemas de recomendação, filtra-se as regras de associação a
partir de um limiar mínimo de suporte, confiança e \textit{lift}. Para gerar uma
recomendação a partir de uma transação em curso, basta buscar pelas regras de
associação em que essa transação seja o subconjunto antecedente, cujas regas com
maior confiança são as recomendadas.


O suporte de um conjunto de itens genérico é definido como a razão entre a
quantidade de transações em que esse conjunto esteja contido pela quantidade
total~\cite{larose2014discovering}. Por exemplo, para o conjunto de itens X:

\begin{equation}
s(X) = \frac{|\{T_i \in \mathcal{T} : X \subseteq T_i\}|}{|\mathcal{T}|} = P(X)
\end{equation}

Por sua vez, o suporte, a confiança e o \textit{lift} da regra de associação são três
propriedades que avaliam a qualidade da mesma~\cite{larose2014discovering}:

\begin{align}
    s(X \Rightarrow Y) &= P( X \cup Y ) \\
    c(X \Rightarrow Y) &= P(Y|X) = \frac{P(X \cup Y)}{P(X)} = \frac{s(X \Rightarrow Y)}{s(X)}  \\
    l(X \Rightarrow Y) &= \frac{P(Y|X)}{P(Y)} = \frac{P(X \cup Y)}{P(X)P(Y)} = \frac{c(X \Rightarrow Y)}{s(Y)}\\
    l(X \Rightarrow Y) &= l(Y \Rightarrow X) 
\end{align}

O suporte indica o quão frequente são as transações que contém X e Y, indicando
pares de conjuntos poucos frequentes que possam ser desconsiderados, ou pares
muito frequentes que devam ser considerados para regras de associação.

A confiança equivale a probabilidade condicional de Y dado X, informando
se há correspondência entre dois conjuntos particulares de itens.

O \textit{lift} avalia o grau de dependência entre X e Y. Quando X e Y são
eventos independentes, o \textit{lift} é igual a 1, uma vez que $P(Y|X) = P(Y)$ e $l(X
\Rightarrow Y) = 1$.

Se o valor do \textit{lift} for maior que 1, significa que a
ocorrência conjunta de X e Y é mais frequente do que seria esperado caso fossem
eventos independentes, uma vez que $P(X \cup Y) > P(X)P(Y)$. Isso indica uma
forte dependência entre X e Y. Por sua vez, um \textit{lift}  menor que 1 indica
que a ocorrência conjunta de X e Y é menos frequente do esperado se fossem
eventos independentes, indicando que são conjuntos substituíveis entre si.

\subsubsection{Regras de Sequência}
Regras de sequência herdam o mesmo raciocínio das regras de associação, de forma
que a sequência de subconjuntos de itens seja considerada~\cite{liu2007web}.

Uma regra de sequência é uma implicação da forma $X \Rightarrow Y$, em que $Y$ é
uma sequência de subconjuntos de itens. $X$ é uma subsequência de $Y$, tal que o
comprimento de $Y$ é maior que o comprimento de $X$. Cada sequência é
compreendida como uma lista ordenada de subconjuntos de itens.

O suporte de uma regra de sequência $X \Rightarrow Y$ em um banco de dados de
sequências $S$ é a fração de sequências em $S$ que contém $Y$. A confiança de
uma regra de sequência $X \Rightarrow Y$ em $S$ é a taxa de sequências em
$S$ que contém $X$ e $Y$.
    
\subsubsection{Recomendação baseada em cadeias de Markov}
Cadeias de Markov são modelos que representam sequências de variáveis aleatórias
correspondentes a estados~\cite{ching2006markov}. Através das probabilidades
associadas a cada estado e das transições entre eles, é possível estimar o
próximo estado mais provável. São aplicados em uma variedade de áreas, sendo
úteis inclusive em sistemas de recomendação baseados em sequências.

Em uma cadeia de Markov de primeira ordem, dado o conjunto de estados
$\mathcal{A} = \{\alpha_1, \alpha_2, \dots, \alpha_n\}$, a probabilidade de
transição de um estado $s_j$ para um estado $s_{j+1}$ é obtida independentemente
dos estados anteriores~\cite{rabiner1989tutorial}:

\begin{equation}
    P(s_{j+1} = \alpha_j | s_j = \alpha_i, s_{j-1} = \alpha_k, \dots) = P(s_{j+1} = \alpha_j | s_j = \alpha_i)
    \label{eq:markov}
\end{equation}
Uma cadeia de Markov de n-ésima ordem está associada a quantidade de memória
necessária para prever o próximo estado. Em uma cadeia de Markov de segunda
ordem, por exemplo, o estado seguinte depende da probabilidade condicional dos
dois estados anteriores.

A partir da equação \ref{eq:markov}, o coeficiente contendo a probabilidade de
transição entre dois estados $i$ e $j$ é dado por $a_{ij}$, enquanto o
coeficiente contendo a probabilidade do estado inicial é dado por $c_i$:
\begin{align}
    a_{ij} &= P(s_{j+1} = \alpha_j | s_j = \alpha_i) \\
    c_i &= P(s_1 = \alpha_i)
\end{align}
Finalmente, de posse dos coeficientes de transição e do estado inicial, a
probabilidade de uma sequência específica ocorrer é calculada pelo
produto dos coeficientes associados a cada estado nela presente.

No caso de um sistema de recomendação, a fase de treinamento envolve o modelo
aprendendo as probabilidades de transição para um subconjunto específico e
isolado de dados, enquanto a fase de predição consiste em determinar o estado
mais relevante com base nos $n$ itens mais recentes na sessão, associados à
ordem do modelo~\cite{aggarwal2016recommender}.

No comparativo, consta uma cadeia de primeira ordem como 
base de comparação, além dos modelos \textit{session-based} Fossil e FPMC,
baseados em cadeias de Markov.



\subsubsection{Árvores de contexto}
\abbrev{VMM}{modelo de Markov de ordem variável}
Uma dificuldade ao aplicar cadeias de Markov de ordem fixa em sistemas de
recomendação é como determinar a ordem ótima do modelo, o que não é um problema
em modelos de Markov de ordem variável (VMMs, do inglês
\textit{variable-order Markov models}), uma vez que a ordem depende do
contexto da sequência ou da recomendação~\cite{mi2016adaptive}.

Árvores de contexto~\cite{willems1995context} foram inicialmente criadas como
uma forma de estimar VMMs, os quais foram inicialmente propostos para resolver
problemas de compressão de dados sem perdas~\cite{begleiter2004prediction}. As
árvores de contexto representam sequências de símbolos como uma hierarquia de
contextos, cujas estatísticas compõem um modelo
preditivo~\cite{garcin2013personalized}. Posteriormente, árvores de contexto
foram utilizadas para tarefas de predição de sequências, inclusive em sistemas
de recomendação.

Ao implementar uma árvore de contexto, primeiramente define-se o conjunto
$\mathcal{S}$ de todas as possíveis sequências de itens. Um sufixo $\xi$ é uma
subsequência contida no final de uma sequência. Por exemplo, na sequência $s = [n_1,
n_2, n_3, n_4]$, o sufixo $\xi = [n_3, i_4]$ é um sufixo de $s$. Dessa forma,
o contexto $S$ é o subconjunto de todas as sequências em $\mathcal{S}$ que contém
$\xi$:
% S = {s ∈ S : ξ ≺ s}
\begin{equation}
    S = \{s \in \mathcal{S} : \xi \prec s\}, S \subset \mathcal{S}
\end{equation}
em que $\prec$ é o operador de precedência.

\forestset{
  red node/.style={
    draw=red,
  },
}

\begin{figure}
    \centering
    \begin{forest}
      for tree={
        circle,
        draw,
        % minimum size=1em,
        % maximum size=10em,
        edge={-latex},
        s sep=10mm
      },
      [<>, red node
        [<$n_1$>, red node
          [\text{<$n_2$, $n_1$>}]
          [\text{<$n_3$, $n_1$>}, red node
            [\text{<$n_2$, $n_3$, $n_1$>}, red node
          ]
          ]
        ]
        [<$n_2$>]
        [<$n_3$>
        [\text{<$n_2$, $n_3$>}]
      ]
      ]
    \end{forest}
    \label{fig:context_tree}
    \caption{Exemplo de uma árvore de contexto. Para a sequência $s = [n_2, n_3, n_1]$, os nós em vermelho representam os contextos com especialistas ativos.}
    \end{figure}

Uma árvore de contexto $\mathcal{T} = (\mathcal{V}, \mathcal{E})$ com nós
$\mathcal{V}$ e arestas $\mathcal{E}$ é uma partição em árvore de todas as
sequências de $\mathcal{S}$ em contextos. Cada nó representa um contexto. Caso
o nó $i$ seja o ancestral do nó $j$, então $S_j \subset S_i$~\cite{mi2018context}.

Cada nó possui um modelo de predição local, denominado especialista (do inglês
\textit{expert}). Um especialista $\mu_i$ é uma função que calcula a
probabilidade da ocorrência do próximo item $n_{t+1}$ dado o contexto $S_i$, igual a
$P_i(n_{t+1} | s_t)$.

Para um contexto $S_i = \{s: \xi_i \prec s_t\}$, os especialistas associados a
nós que compartilham do mesmo sufixo $\xi_i$ são chamados de especialistas
ativos. No exemplo da FIGURA \ref{fig:context_tree}, os contextos em vermelho
representam os especialistas ativos para a sequência destacada. A probabilidade de um especialista é obtida ao multiplicar a probabilidade dos
especialistas ativos $\mathcal{A}(s_t)$
 que incluem o sufixo $\xi$:
\begin{align}
    \mathcal{A}(s_t) &= \{\mu_i : \xi \prec s_t\}\\
    P(n_{t+1} = x | s_t) &= \sum_{i \in \mathcal{A(s_t)}} u_i(s_t)  P_i(n_{t+1} = x | s_t)
\end{align}

Tal que $u_i (s_t) = P(i|s_t)$ é a probabilidade do i-ésimo especialista
relevante. Esse valor é obtido a partir de pesos que representam a utilidade de
cada contexto da sequência em questão. A explicação detalhada da obtenção
desses pesos consta em \citet{mi2018context}.





% A context tree
% T = (V, E) with nodes V and edges E is a partition tree over all
% contexts of S. Each node i ∈ V in the context tree corresponds
% to a context Si . If node i is the ancestor of node j then Sj ⊂ Si .










\section{Sistemas de Recomendação Baseados em Conteúdo}

Sistemas de recomendação baseados em conteúdo são utilizados em aplicações cujos
itens e usuários são descritos por um conjunto de atributos. Por exemplo, um
sistema de recomendação de filmes pode utilizar atributos como gênero, diretor,
país de origem e ano de lançamento. Nesse caso, o conteúdo dos itens que o
usuário avaliou e a similaridade entre os atributos são
suficientes para gerar as recomendações.

Uma segunda aplicação típica de sistemas baseados em conteúdo é a recomendação
de itens com descrição textual e sem atributos explícitos. Documentos,
mídias em texto, páginas \textit{web} também fazem parte desse tipo de
aplicação. Nesses casos, é necessário extrair e selecionar termos e símbolos
mais representativos do conteúdo.


Ao contrário da filtragem colaborativa, os sistemas baseados em conteúdo não
dependem de avaliações de outros usuários para gerar recomendações, o que é uma
vantagem em cenários de \textit{cold-start} ou com poucos usuários na
plataforma.

Em um sistema baseado em conteúdo,
utilizar todos os atributos disponíveis não é necessariamente a melhor
abordagem, uma vez que isso acarreta em maior dimensionalidade do espaço de
atributos, maior custo computacional e maior risco de \textit{overfitting} do
modelo.


A seleção de atributos, ou \textit{feature selection}, consiste em definir qual
o conjunto ótimo de atributos dado o conjunto completo de
atributos e uma função objetiva que deve ser minimizada ou maximizada. A função
objetiva pode ser o índice de Gini, a entropia, a informação mútua, etc.

\subsubsection{kNN}
\abbrev{kNN}{\textit{k-nearest neighbors}}
O algoritmo kNN (do inglês \textit{k-nearest neighbors}) é um método de
aprendizado supervisionado utilizado geralmente para tarefas de classificação. O
algoritmo considera a similaridade ou a proximidade entre vetores de atributos
para classificá-los.

No caso de um SBRS, o algoritmo kNN calcula as similaridades de determinada
sessão vigente com todas as sessões disponíveis no conjunto de treinamento. Essa
pontuação de similaridade é calculada a partir da quantidade de itens comuns
entre as sessões. Ao filtrar as $k$ sessões mais similares à sessão vigente, são
identificados os $k$ vizinhos mais próximos. Esse procedimento é realizado
justamente no modelo skNN~\cite{ludewig_2019}:

Os itens contidos nessas $k$ sessões são os candidatos à recomendação. Os
itens mais recomendados serão aqueles que acumularem mais ocorrências entre as
$k$ sessões, ponderados pela pontuação de similaridade de suas
respectivas sessões.

Uma definição formal \cite{murphy} para o algoritmo kNN consiste na probabilidade
condicional de uma saída $y$ obter determinada classificação $c$ dado um conjunto
de treinamento $\mathcal{D}$ e um novo vetor de entrada $x$:

\begin{equation}
    p(y=c|x, \mathcal{D}) = \frac{1}{K} \sum_{n \in N_k (x, \mathcal{D})} \mathbb{I}(y_n = c)
\end{equation}
em que $\mathcal{D} = \{(x_i, y_i )\}^{N}_{i=1}$ estipula a bijeção
entre um vetor de entrada e sua saída correspondente, $N_k(x, \mathcal{D})$
são os índices dos $K$ vizinhos mais próximos de $x$ em $\mathcal{D}$ e $\mathbb{I}$ é a função
indicadora caso o item obtenha a classificação estipulada.

\subsubsection{skNN e vskNN}
\abbrev{skNN}{\textit{Session-Based} kNN}
\abbrev{vskNN}{\textit{Vector Multiplication Session-Based} kNN}
Para modelos de recomendação baseados em sessão, diferentes abordagens inspiradas em kNN
foram propostas, a exemplo do skNN (\textit{Session-Based} kNN) e do vsKNN
(\textit{Vector Multiplication Session-Based} kNN).

o modelo skNN considera todos os itens da sessão ao calcular a similaridade
entre as sessões. Todos os itens tem o mesmo peso e contribuem de forma
igualitária na pontuação de similaridade, independentemente de sua
recência ou de sua posição~\cite{ludewig_2019}. A pontuação de um item candidato para a sessão
é dado pelo somatório das similaridades entre a sessão vigente em relação às sessões vizinhas
que contém o item candidato:

\begin{equation}
    \hat{r}_{\text{skNN}}(i, s) = \sum_{n \in N_s} \text{sim}(s,n) \times \mathbb{I}_n(i)
\end{equation}
em que $N_s$ é o conjunto de sessões vizinhas e $\mathbb{I}_n(i)$ é a função
indicadora caso o item pertença à sessão $n$.

A vizinhança de cada sessão é definida a partir da maior
similaridade entre as sessões. Essa abordagem difere do ikNN
(\textit{item-based} KNN), que considera a similaridade entre os itens de cada
sessão. 

O vsKNN, por sua vez, concede maior importância a eventos mais recentes,
aplicando uma decaimento sobre o peso dos eventos. Quanto mais antigo, maior o
decaimento. O nome ``\textit{Vector Multiplication}'' se dá pelo cálculo da
similaridade com a sessão $s$, representada como um vetor de valores reais em
razão do decaimento.


\subsubsection{STAN e VSTAN}
O modelo STAN (\textit{sequence and time-aware neighborhood}) é uma extensão do
SKNN com três propriedades adicionadas às pontuações: posição dos itens na
sessão ativa, recência da sessão vizinha e posição do item candidato na sessão
vizinha~\cite{garg2019sequence}. Cada um desses componentes possui sua própria função de decaimento.

Por sua vez, o VSTAN~\cite{ludewig_2021} combina características dos modelos STAN e vsKNN,
adicionando dois novos pesos. O primeiro peso é associado à posição do último
item da sessão ativa que coexiste na sessão vizinha. Além disso, um segundo peso
é obtido a partir da medida do inverso da frequência do termo no documento (IDF,
do inglês \textit{inverse document frequency}). O IDF é uma medida de raridade
de um termo em um documento, em que termos muito recorrentes são penalizados.
É obtido a partir do logaritmo do inverso da frequência do termo em um
conjunto de documentos:
\begin{equation}
    \text{IDF}(t) = \log \frac{N}{n_t}
\end{equation}
em que $N$ é a quantidade de documentos e $n_t$ é a quantidade de documentos
que contém o termo $t$. No contexto do vsKNN, o IDF é utilizado para penalizar
itens muito recorrentes no conjunto de treinamento.