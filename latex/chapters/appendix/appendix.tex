\chapter{Otimização dos hiperparâmetros}

\section{\textit{session-based}, \textit{next-item}}
\subsubsection{skNN e vskNN}
\abbrev{IDF}{\textit{Inverse Document Frequency}}
Em que $k$ é a quantidade de vizinhos os quais a pontuação dos itens é
calculada, $N$ é o tamanho da amostra de sessões utilizadas para calcular os
vizinhos mais próximos, $Sim$ é a função de similaridade, $W_{atual}$ é a função
de decaimento que determina peso das ações individuais na sessão atual,
$W_{candidato}$ é a função de decaimento que determina o peso dos itens
candidatos de uma sessão vizinha e selecionados por itens clicados menos
recentemente na sessão atual e $IDF$ é o peso associado à frequência inversa do
documento (\textit{Inverse Document Frequency}).

\begin{table}[htbp]
    \centering
    \begin{tabular}{|c|c|c|c|c|c|c|c|}
      \hline
      \multicolumn{3}{|c|}{Parâmetros} & \multicolumn{4}{c|}{Métricas @10} \\
      \hline
      k & N & Sim & MRR & HR & Cov & Pop\\
      \hline
      50 & 500 & Cosseno & \textbf{0,172} & 0.571 & \textbf{0,645} & \textbf{0,204} \\
      \hline
      50 & 500 & Jaccard & 0,165 & 0,534 & 0,534 & 0,289 \\
      \hline
      1000 & 500 & Jaccard & 0,166 & 0,534 & 0,534 & 0,279 \\
      \hline
      1500 & 500 & Cosseno & 0,160 & 0,511 & 0,529 & 0,283 \\
    %   \hline
    %   50 & 10000 & Jaccard & \textbf{0.176} & \textbf{0.587} & \textbf{0.700} & 0.210 \\
      \hline
      100 & 2500 & Cosseno & \textbf{0,172} & \textbf{0,577} & 0.611 & 0.232 \\
      \hline
    \end{tabular}
    \caption{\textit{session-based} kNN (sKNN)}
  \end{table}

%   vsknn-k=1500-sample_size=2500-weighting=same-weighting_score=div-idf_weighting=10
% vsknn-k=1500-sample_size=500-weighting=quadratic-weighting_score=log-idf_weighting=False
% vsknn-k=1500-sample_size=500-weighting=same-weighting_score=linear-idf_weighting=10
% mrr10 0.1462788940342183 0.15546196009033428 0.14208841138517056
% hr10 0.5071205750712058 0.4885392648853926 0.48528414485284144
% cov10 0.5794019933554817 0.5242524916943522 0.574750830564784
% pop10 0.24168610581871308 0.28216181416939157 0.21287151000442397

\begin{table}[htbp]
\centering
  \begin{tabular}{|c|c|c|c|c|c|c|c|c|}
    \hline
    \multicolumn{5}{|c|}{Parâmetros} & \multicolumn{4}{c|}{Métricas @10} \\
    \hline
    k & N & $W_{atual}$ & $W_{candidato}$ & IDF & MRR & HR & Cov & Pop \\
    \hline
    50 & 500 & Linear & log & 5 & 0,156 & 0,522  & 0,638 & \textbf{0,183} \\
    \hline
    50 & 2500 & Quadrático & Div & 1 & 0,157 & 0,532 & 0,653 & 0,200 \\
    \hline
    50 & 2500 & N/A & Log & 1 & \textbf{0,160} & \textbf{0,557} & \textbf{0,657} & 0,200 \\
    \hline
    1500 & 2500 & N/A & Div & 10 & 0,146 & 0,507 & 0,580 & 0,242 \\
    \hline
    1500 & 500 & Quadrático & Log & N/A & 0,142 & 0,489 & 0,524 & 0,282 \\
    \hline
    1500 & 500 & N/A & Linear & 10 & 0,142 & 0,485 & 0,575 & 0,213 \\
    \hline
  \end{tabular}
  \caption{\textit{Vector multiplication session-based} kNN (vsKNN)}
\end{table}

\subsubsection{Regras de sequência}
Métricas são a quantidade de passos e a função de pesos.
\begin{table}[htbp]
    \centering
    \begin{tabular}{|c|c|c|c|c|c|}
        \hline
        \multicolumn{2}{|c|}{Parâmetros} & \multicolumn{4}{c|}{Métricas} \\
        \hline
        Passos & W & MRR@10 & HR@10 & Cov@10 & Pop@10 \\
        \hline
        6 & Div & 0.264 & \textbf{0,533} & 0.502 & 0.286 \\
        \hline
        6 & Log & 0.255 & 0.519 & 0.490 & 0.293 \\
        \hline
        6 & Quadrático & \textbf{0,270} & \textbf{0,533} & 0.516 & 0.275 \\
        \hline
        11 & Div & 0.264 & 0.532 & 0.503 & 0.287 \\
        \hline
        11 & Linear & 0.253 & 0.519 & 0.488 & 0.293 \\
        \hline
        11 & Log & 0.254 & 0.516 & 0.490 & \textbf{0,296} \\
        \hline
        12 & Quadrático & \textbf{0,270} & \textbf{0,533} & \textbf{0,517} & 0.275 \\
        \hline
        \end{tabular}
    \caption{Regras de sequência}
\end{table}


\subsubsection{STAN}
% stan-k=2000-sample_size=2500-lambda_spw=3.62-lambda_snh=100-lambda_inh=7.24
% stan-k=100-sample_size=2500-lambda_spw=1.81-lambda_snh=40-lambda_inh=0.197
$stan_1$ é o modelo com $k$ igual a 2000, $N$ igual a 2500, $\lambda_{\text{spw}}$ igual a 3,62.
$stan_2$ é o modelo com $k$ igual a 100, $N$ igual a 2500, $\lambda_{\text{spw}}$ igual a 1,81.


\begin{table}[htbp]
    \centering
    \begin{tabular}{|c|c|c|c|c|c|c|c|c|}
      \hline
      \multicolumn{5}{|c|}{Parâmetros} & \multicolumn{4}{c|}{Métricas @10} \\
      \hline
      k & N & $\lambda_{\text{spw}}$ & $\lambda_{\text{snh}}$ & $\lambda_{\text{inh}}$ & MRR & HR & Cov & Pop \\
      \hline
      2000 & 2500 & 3,62 & 100 & 7,24 & \textbf{0,202} & \textbf{0,637} & 0,217 & 0,277 \\
      \hline
      200 & 1000 & 7,24 & 2,5 & 7,24 & 0,201 & 0,580 & 0,231 & 0,236 \\
      \hline
      200 & 2500 & 7,24 & 100 & 1,81& 0,190 & \textbf{0,637} & 0,238 & 0,217 \\
      \hline
      500 & 1000 & 7,24 & 80 & 0,905 & 0,188 & 0,660 & 0,226 & 0,235 \\
      \hline
      100 & 5000 & $10^{-5}$ & 100 & 1,81 & 0,174 & 0,523 & \textbf{0,268} & \textbf{0,189} \\
      \hline
      100 & 2500 & 1,81 & 40 & 3,62 & 0,197 & 0,627 & 0,245 & 0,202 \\
      \hline

    \end{tabular}
    \caption{stan}
  \end{table}


\subsubsection{VSTAN}
$vstan_1$ é o modelo com $k$ igual a 1000 e $N$ igual a 5000. 
$vstan_2$ é o modelo com $k$ igual a 2000 e $N$ igual a 1000. 


\begin{table}[htbp]
    \centering
    \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|}
      \hline
      \multicolumn{8}{|c|}{Parâmetros} & \multicolumn{4}{c|}{Métricas @10} \\
      \hline
      k & N & Sim & $\lambda_{\text{spw}}$ & $\lambda_{\text{snh}}$ & $\lambda_{\text{inh}}$ & $\lambda_{\text{ipw}}$ & $\lambda_{\text{IDF}}$ & MRR & HR & Cov & Pop \\
      \hline
      1500 & 1000 & Cosseno & 10 & 5 & 10 & 5 & False & 0,198 & 0,439 & 0,601 & 0,237 \\
      \hline
      1000 & 5000 & Cosseno & 10 & 40 & 5 & $10^{-5}$ & False & \textbf{0,202} & \textbf{0,473} & 0,629 & 0,238 \\
      \hline
      100 & 10000 & Cosseno & 2,5 & 100 & 2,5 & 2,5 & False & 0,194 & 0,456 & 0,629 & 0,196 \\
      \hline
      2000 & 1000 & Vetorial & 10 & 100 & 0,625 & 1,25 & False & 0,187 & 0,447 & \textbf{0,644} & 0,252 \\
      \hline
      1500 & 1000 & Vetorial & 5 & 100 & 5 & 5 & False & 0,187 & 0,445 & 0,639 & 0,213 \\
      \hline
      1000 & 10000 & Vetorial & $10^{-5}$ & 10 & 10 & 5 & 1 & 0,180 & 0,422 & 0,542 & \textbf{0,173} \\
      \hline
    \end{tabular}
    \caption{vstan}
  \end{table}

\subsubsection{smf}
$smf_{1}$ é o modelo com função objetiva BPR e skip igual a 0,2.
$smf_{2}$ é o modelo com função objetiva TOP1 com taxa de aprendizado igual a 0,05.
\begin{table}[htbp]
  \centering
  \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|}
    \hline
      \multicolumn{6}{|c|}{Parâmetros} & \multicolumn{4}{c|}{Métricas @10} \\
      \hline
      Obj. & at. & d. & skip & m & l.r. & MRR & HR & Cov & Pop \\
      \hline
      BPR & Linear & 0,3 & 0,2 & 0 & 0,01 & \textbf{0,359} & 0,614 & 0,183 & 0,269 \\
      \hline
      BPR & Linear & 0,3 & 0 & 0 & 0,01 & 0,358 & 0,610 & 0,191 & 0,267 \\
      \hline
      TOP1 & Linear & 0,1 & 0,3 & 0,1 & 0,05 & 0,344 & \textbf{0,654} & 0,282 & 0,236 \\
      \hline
      TOP1 & Linear & 0 & 0,3 & 0,8 & 0,004 & 0,350 & 0,644 & 0,196 & 0,273 \\
      \hline
      BPR & Linear & 0,3 & 0 & 0 & 0,07 & 0,319 & 0,627 & \textbf{0,306} & \textbf{0,231} \\
      \hline
      \end{tabular}
      \caption{smf}
\end{table}

\subsubsection{NARM}
$\text{NARM}_{1}$ é o modelo com 100 unidades ocultas e taxa de aprendizado 0,006.
$\text{NARM}_{2}$ é o modelo com 50 unidades ocultas e taxa de aprendizado 0,01.

\begin{table}[htbp]
  \centering
  \begin{tabular}{|c|c|c|c|c|c|c|c|}
    \hline
      \multicolumn{4}{|c|}{Parâmetros} & \multicolumn{4}{c|}{Métricas @10} \\
      \hline
      Epochs & fatores & un. ocultas & lr & MRR & HR & Cov & Pop \\
      \hline
      20 & 50 & 100 & 0,006 & \textbf{0,197} & \textbf{0,392} & 0,340 & 0,203 \\
      \hline
      20 & 50 & 100 & 0,005 & 0,195 & \textbf{0,392} & 0,330 & 0,205 \\
      \hline
      20 & 50 & 50 & 0,01 & 0,176 & 0,365 & \textbf{0,363} & 0,192 \\
      \hline
      20 & 100 & 50 & 0,002 & 0,155 & 0,342 & 0,344 & \textbf{0,182} \\
      \hline
      \end{tabular}
      \caption{NARM}
\end{table}

\subsubsection{GNN}
otimização para GNN com \textit{hidden size} igual a 100, \textit{out size} igual a 100,
\textit{step} igual a 1, \textit{nonhybrid} igual a True, \textit{batch size} igual a 100,
\textit{n epoch} igual a 10, \textit{batch predict} igual a True.

O modelo $\text{GNN}_{1}$ é o modelo com taxa de aprendizado igual a 0,004.
O modelo $\text{GNN}_{2}$ é o modelo com taxa de aprendizado igual a 0,006.
\begin{table}[htbp]
  \centering
  \begin{tabular}{|c|c|c|c|c|c|c|c|}
    \hline
      \multicolumn{4}{|c|}{Parâmetros} & \multicolumn{4}{c|}{Métricas @10} \\
      \hline
      lr & l2 & lr dc & lr dc step & MRR & HR & Cov & Pop \\
      \hline
      0,004 & $6 \times 10^{-6}$ & 0,366 & 5 & \textbf{0,437} & \textbf{0,713} & 0,308 & 0,231 \\
      \hline
      0,006 & $3 \times 10^{-6}$ & 0,1 & 5 & 0,422 & 0,643 & \textbf{0,367} & 0,216 \\
      \hline
      0,008 & $8 \times 10^{-5}$ & 0,455 & 3 & 0,410 & 0,648 & 0,360 & \textbf{0,206} \\
      \hline
      \end{tabular}
      \caption{GNN}
\end{table}

\subsubsection{NextItNet}
$nextitnet_1$ é o modelo com taxa de aprendizado igual a 0,0007, $nextitnet_2$ é
o modelo com taxa de aprendizado igual a 0,0009.
\begin{table}[htbp]
  \centering
  \begin{tabular}{|c|c|c|c|c|c|c|}
    \hline
      \multicolumn{3}{|c|}{Parâmetros} & \multicolumn{4}{c|}{Métricas @10} \\
      \hline
      lr & it. & neg. & MRR & HR & Cov & Pop \\
      \hline
      0,0007 & 30 & True & \textbf{0,308} & 0,561 & 0,227 & 0,299 \\
      \hline
      0,0009 & 30 & False & 0,304 & \textbf{0,576} & 0,263 & 0,294 \\
      \hline
      0,005 & 30 & True & 0,197 & 0,470 & \textbf{0,270} & 0,278 \\
      \hline
      0,01 & 20 & True & 0,132 & 0,291 & 0,193 & \textbf{0,252} \\
      \hline
    \end{tabular}
    \caption{NextItNet}
\end{table}

\subsubsection{STAMP}

% Metrics	MRR@10:  HitRate@10:    Coverage@10:	Popularity@10:
% stamp-decay_rate=0.5-init_lr=0.008	0.412970  0.64638    0.3116279	0.22910
% stamp-decay_rate=0.6-init_lr=0.009	0.393594  0.62547    0.3401993	0.22372
% stamp-decay_rate=0.0-init_lr=0.006	0.360398 0.58935 0.4079734	0.19806
n epochs igual a 30. O modelo $\text{STAMP}_{1}$ e $\text{STAMP}_{2}$
são o primeiro e segundo modelos na tabela.

\begin{table}[htbp]
  \centering
  \begin{tabular}{|c|c|c|c|c|c|}
    \hline
      \multicolumn{2}{|c|}{Parâmetros} & \multicolumn{4}{c|}{Métricas @10} \\
      \hline
      lr inicial & decay & MRR & HR & Cov & Pop \\
      \hline
      0,008 & 0,5 & \textbf{0,413} & \textbf{0,646} & 0,312 & 0,229 \\
      \hline
      0,006 & 0 & 0,360 & 0,589 & \textbf{0,408} & \textbf{0,198} \\
      \hline
    \end{tabular}
    \caption{STAMP}
\end{table}


\subsubsection{GRU4Rec}

% Metrics	MRR@10: HitRate@10:  Coverage@10:	Popularity@10:
% dropout_p_hidden=0.2-momentum=	0.120705 0.2395437 0.55415	0.044515
% dropout_p_hidden=0.5-momentum=	0.1030222 0.18821 0.52358	0.052286

Função de custo BPR max, função de ativação final ELU, \textit{dropout} igual a 0,5,
\textit{momentum} igual a 0, \textit{constrained embedding} igual a False.
\begin{table}[htbp]
  \centering
  \begin{tabular}{|c|c|c|c|c|c|}
    \hline
      \multicolumn{2}{|c|}{Parâmetros} & \multicolumn{4}{c|}{Métricas @10} \\
      \hline
      lr  & dropout & MRR & HR & Cov & Pop \\
      \hline
      0,09  & 0,2 & \textbf{0,121} & \textbf{0,240} & \textbf{0,554} & \textbf{0,045} \\
      \hline
      0,04  & 0,5 & 0,103 & 0,188 & 0,524 & 0,052 \\
      \hline
    \end{tabular}
    \caption{GRU4Rec}
\end{table}



\subsubsection{CSRM}

% Metrics	MRR@10: HitRate@10:  Coverage@10:	Popularity@10:
% dropout_p_hidden=0.2-momentum=	0.120705 0.2395437 0.55415	0.044515
% dropout_p_hidden=0.5-momentum=	0.1030222 0.18821 0.52358	0.052286
\begin{table}[htbp]
  \centering
  \begin{tabular}{|c|c|c|c|c|c|c|c|}
    \hline
      \multicolumn{4}{|c|}{Parâmetros} & \multicolumn{4}{c|}{Métricas @10} \\
      \hline
      un. ocultas & \textit{epochs}  & lr  & m.s. & MRR & HR & Cov & Pop \\
      \hline
      100  & 10 & 0,0008 & 256 & \textbf{0,167} & 0,319 & \textbf{0,328} & \textbf{0,151} \\
      \hline
      100  & 10 & 0,0005 & 128 & 0,148 & \textbf{0,323} & 0,148 & 0,302 \\
      \hline
    \end{tabular}
    \caption{CSRM}
\end{table}

\newpage


% \subsubsection{GRU4Rec}
% Otimização com \textit{n epochs} igual a 20, \textit{factors} igual a 50. O
% modelo $\text{GRU4Rec}_{1}$ é o modelo com \textit{hidden units} igual a 100 e
% taxa de aprendizado igual a 0,006. O modelo $\text{GRU4Rec}_{2}$ é o modelo com
% \textit{hidden units} igual a 50 e taxa de aprendizado igual a 0,01.

% \begin{table}[htbp]
%   \centering
%   \begin{tabular}{|c|c|c|c|c|c|}
%       \hline
%       \multicolumn{2}{|c|}{Parâmetros} & \multicolumn{4}{c|}{Métricas @10} \\
%       \hline
%       un. ocultas & lr & MRR & HR & Cov & Pop \\
%       \hline
%       100 & 0,006 & \textbf{0,198} & \textbf{0,392} & 0,340 & 0,203 \\
%       \hline
%       50 & 0,01 & 0,176 & 0,365 & \textbf{0,363} & \textbf{0,192} \\
%       \hline
%     \end{tabular}
%     \caption{GRU4Rec}
% \end{table}

\section{\textit{session-aware}, \textit{next-item}}

% Metrics	MRR@10:	HitRate@10:	Coverage@10:	Popularity@10:
% steps=5-weighting=quadratic-boost_own_sessions=3.9	0.3301 0.5561 0.7293	0.1861
% steps=7-weighting=quadratic-boost_own_sessions=1.7	0.32566 0.553 0.7351	0.1873
% steps=2-weighting=div-boost_own_sessions=3.7	0.3285 0.5377 	0.7176	0.1825
A otimização indica que o modelo com 5 passos na tabela \ref{opt:seq_rules}
retorna as melhores métricas. Ao realizar o \textit{finetuning} para esse
obtemos o modelo $usr$ com \textit{remind sessions number} igual a 8 $W_{base}$
igual a 2 e $W_{IRec}$ igual a 8.

\begin{table}[htbp]
  \centering
  \begin{tabular}{|c|c|c|c|c|c|c|}
    \hline
      \multicolumn{3}{|c|}{Parâmetros} & \multicolumn{4}{c|}{Métricas @10} \\
      \hline
      Passos & W & $\lambda_{\text{boost}}$ & MRR & HR & Cov & Pop \\
      \hline
      5 & Quadrático & 3,9 & \textbf{0,330} & \textbf{0,556} & 0,729 & 0,186 \\
      \hline
      7 & Quadrático & 1,7 & 0,326 & 0,553 & \textbf{0,735} & 0,187 \\
      \hline
      2 & Div & 3,7 & 0,329 & 0,538 & 0,718 & \textbf{0,182} \\
      \hline
      \end{tabular}
      \caption{Regras de sequência}
      \label{opt:seq_rules}
\end{table}
\begin{table}
  \centering
  \begin{tabular}{|c|c|c|c|c|c|c|}
    \hline
      \multicolumn{3}{|c|}{Parâmetros} & \multicolumn{4}{c|}{Métricas @10} \\
      \hline
      r.s.n. & $W_{base}$ & $W_{IRec}$ & MRR & HR & Cov & Pop \\
      \hline
      8 & 2 & 8 & \textbf{0,362} & \textbf{0,625} & 0,732 & \textbf{0,339} \\
    \hline
     10 & 1 & 9 & 0,360 & 0,607 & \textbf{0,751} & 0,333 \\
     \hline
  \end{tabular}
  \caption{\textit{Finetuning} para o modelo de regras de sequência com 5 passos.}
\end{table}

\subsubsection{Modelos kNN}
O modelo UVSTAN com $k$ igual a 100, $N$ igual a 2500, $Sim$ igual a cosseno,
$\lambda_{\text{spw}}$ igual a 7,24, $\lambda_{\text{snh}}$ igual a 80,
$\lambda_{\text{inh}}$ igual a 0,4525, $\lambda_{\text{ipw}}$ igual a 0,4525,
$\lambda_{\text{IDF}}$ igual a 5, \textit{extend session length} igual a 1,
$\lambda_{\text{boost}}$ igual a 2,1, \textit{reminders} igual a True,
\textit{remind strategy} igual a hybrid, \textit{remind sessions num} igual a 9,
\textit{weight base} igual a 2, \textit{weight IRec} igual a 8 e \textit{weight
SSim} igual a 7.

O modelo VSKNN com $k$ igual a 50, $N$ igual a 500, $Sim$ igual a cosseno,
\textit{weighting} igual a same, \textit{weighting score} igual a linear,
\textit{idf weighting} igual a 2, \textit{extend session length} igual a 11,
$\lambda_{\text{boost}}$ igual a 2,9.

% extend_session_length=2=recency-remind_mode=top-remind_sessions_num=9-reminders_num=3
O modelo USTAN com $k$ igual a 200, $N$ igual a 1000, $\lambda_{\text{spw}}$
igual a 0,905, $\lambda_{\text{snh}}$ igual a 100, $\lambda_{\text{inh}}$ igual a
0,905, \textit{extend session length} igual a 2, \textit{boost own sessions}
igual a 3,9, \textit{reminders} igual a True, \textit{remind strategy} igual a
\textit{recency}, \textit{remind mode} igual a \textit{top}, \textit{remind
sessions num} igual a 9 e \textit{reminders num} igual a 3.

\begin{table}[htbp]
  \centering
  \begin{tabular}{|c|c|c|c|c|}
      \hline
      \multicolumn{1}{|c|}{} & \multicolumn{4}{c|}{Métricas @10} \\
      \hline
      Modelo & MRR & HR & Cov & Pop \\
      \hline
      UVSTAN & 0,347 & 0,606 & \textbf{0,896} & \textbf{0,159} \\
      \hline
      UVSKNN & 0,319 & 0,624 & 0,844 & 0,184 \\
      \hline
      USTAN & \textbf{0,390} & \textbf{0,646} & 0,680 & 0,386 \\
      \hline
      \end{tabular}
      \caption{Modelos kNN}
\end{table}



\subsubsection{Modelos de redes neurais}
Modelo IIRNN com \textit{max epoch} igual a 100, \textit{dropout pkeep} igual a
0,6, taxa de aprendizado igual a 0,006, \textit{max session representation} igual
a 15, \textit{use last hidden state} igual a True e \textit{embedding size} igual
a 100.

Modelo NFCS com \textit{window size} igual a 4, \textit{max nb his sess} igual a
2 e \textit{att alpha} igual a 1.

Modelo NSAR com \textit{num epoch} igual a 20, \textit{batch size} igual a 64,
\textit{keep pr} igual a 0,25, taxa de aprendizado igual a 0,005 e \textit{hidden
units} igual a 100.

Modelo UGRU4Rec com \textit{loss} igual a top1-max, \textit{final act} igual a
linear, \textit{dropout p hidden} igual a 0,1, \textit{momentum} igual a 0,0,
taxa de aprendizado igual a 0,03, \textit{constrained embedding} igual a True e
\textit{extend session length} igual a 5.

Modelo HGRU4Rec com 100 camadas de sessões e 100 camadas de usuários, função de
custo top1-max, função de ativação final tangente hiperbólica,
\textit{dropout p hidden usr} igual a 0,4, \textit{dropout p hidden ses} igual a
0,2, \textit{dropout p init} igual a 0,1, \textit{momentum} igual a 0,2, taxa de
aprendizado igual a 0,03, \textit{user propagation mode} igual a all e
\textit{batch size} igual a 5.


Modelo SHAN com \textit{iter} igual a 100, \textit{global dimension} igual a
100, $\lambda_{\text{uv}}$ igual a 0,0009 e $\lambda_{\text{a}}$ igual a 10.

O modelo UNARM com \textit{n epochs} igual a 20, \textit{factors} igual a 100,
\textit{lr} igual a 0,008 e \textit{extend session length} igual a 19. $W_{base}$
igual a 1 e $W_{IRec}$ igual a 2, \textit{remind sessions num} igual a 5.

\begin{table}[htbp]
  \centering
  \begin{tabular}{|c|c|c|c|c|}
    \hline
      \multicolumn{1}{|c|}{} & \multicolumn{4}{c|}{Métricas @10} \\
      \hline
      Modelo & MRR & HR & Cov & Pop \\
      \hline
      IIRNN & \textbf{0,368} & \textbf{0,591} & 0,813 & 0,190 \\
      \hline
      NCFS & 0,306 & 0,545 & 0,694 & 0,211 \\
      \hline
      NSAR & 0,285 & 0,513 & 0,683 & 0,197 \\
      \hline
      UGRU4Rec & 0,208 & 0,381 & \textbf{0,945} & \textbf{0,059} \\
      \hline
      HGRU4Rec & 0,194 & 0,319 & 0,912 & 0,061 \\ 
      \hline
      SHAN & 0,200 & 0,394 & 0,346 & 0,256 \\
      \hline
      UNARM & 0,348 & 0,560 & 0,796 & 0,298 \\
      \hline
      \end{tabular}
      \caption{Modelos de redes neurais}
      \label{tab:nn_models_aware}
\end{table}


\section{\textit{session-based}, \textit{remaining items}}

A duração da otimização para cada modelo consta na tabela
\ref{tab:duration_opt_remaining}. Todas as otimizações foram realizadas com
40 iterações.

\begin{table}[htbp]
  \centering
  \begin{tabular}{|c|c|c|c|c|c|c|c|c|}
      \hline
      GNN & GRU4Rec & NARM & NextItNet & STAMP & SMF & sr & sKNN & vsKNN \\
      \hline
      2h07 & 2h47 & 8h57 & 1h28 & 0h26 & 3h28 & 0h01 & 0h04 & 0h03 \\
      \hline
      \end{tabular}
      \caption{Duração da otimização em horas e minutos para cada modelo.}
      \label{tab:duration_opt_remaining}
\end{table}

\subsubsection{GNN}
GNN com \textit{hidden size} igual a 100, \textit{out size} igual a 100,
\textit{step} igual a 1, \textit{nonhybrid} igual a True, \textit{batch size}
igual a 100, \textit{n epoch} igual a 10, \textit{batch predict} igual a True.
Resultados na tabela \ref{opt:GNN_rem}. O modelo selecionado é o com NDCG@10 igual a 0,555.

\begin{table}[htbp]
  \centering
  \begin{tabular}{|c|c|c|c|c|c|c|c|}
    \hline
      \multicolumn{4}{|c|}{Parâmetros} & \multicolumn{4}{c|}{Métricas @10} \\
      \hline
      lr & l2 & $\text{lr}_\text{dc}$ &passo do $\text{lr}_\text{dc}$ & MAP & NDCG & Cov & Pop \\
      \hline
      0,008 & $7 \times 10^{-5}$ & 0,455 & 5 & \textbf{0,093} & 0,548 & 0,300 & 0,239 \\
      \hline
      0,005 & $6 \times 10^{-6}$ & 0,722 & 7 & 0,092 & \textbf{0,555} & 0,322 & 0,228 \\
      \hline
      % lr=0.001-l2=1e-05-lr_dc=0.36666667-lr_dc_step=7 0.07953467318486326 0.5077164468988811	0.3780730897009967	0.2178242589413821
      0,001 & $1 \times 10^{-5}$ & 0,366 & 7 & 0,080 & 0,508 & \textbf{0,378} & 0,218 \\
      \hline
      0,007 & $9 \times 10^{-6}$ & 0,544 & 3 & 0,090 & 0,545 & 0,320 & \textbf{0,217} \\
      \hline
\end{tabular}
      \caption{GNN}
      \label{opt:GNN_rem}
\end{table}

\subsubsection{GRU4Rec}

Os parâmetros da tabela são: função de custo, função de ativação final,
\textit{dropout}, \textit{momentum}, \textit{constrained embedding}, respectivamente.
Resultados na tabela \ref{opt:GRU4Rec_rem}.

\begin{table}[htbp]
  \centering
  \begin{tabular}{|c|c|c|c|c|c|c|c|c|}
    \hline
      \multicolumn{5}{|c|}{Parâmetros} & \multicolumn{4}{c|}{Métricas @10} \\
      \hline
      custo & final & \textit{dropout} & \textit{momentum} & c.e. & MAP & NDCG & Cov & Pop \\
      \hline
      BPR & linear & 0,2 & 0,0 & True & \textbf{0,024} & \textbf{0,176} & 0,530 & 0,049 \\
      \hline
      TOP1 & ELU & 0,5 & 0,0 & False & 0,022 & 0,035 & 0,162 & 0,039 \\
      \hline
      TOP1 & ELU & 0,5 & 0,3 & True & 0,010 & 0,075 & \textbf{0,614} & \textbf{0,018} \\
      \hline
\end{tabular}
      \caption{GRU4Rec}
      \label{opt:GRU4Rec_rem}
\end{table}

\subsubsection{NARM}
Otimização com 20 epochs. Resultados na tabela \ref{opt:NARM_rem}.

\begin{table}[htbp]
  \centering
  \begin{tabular}{|c|c|c|c|c|c|c|}
    \hline
      \multicolumn{3}{|c|}{Parâmetros} & \multicolumn{4}{c|}{Métricas @10} \\
      \hline
      fatores & unidades ocultas & lr & MAP & NDCG & Cov & Pop \\
      \hline
      100 & 100 & 0,004 & \textbf{0,041} & 0,275 & 0,332 & 0,210 \\
      \hline
      100 & 100 & 0,008 & 0,040 & \textbf{0,276} & 0,354 & \textbf{0,188} \\
      \hline
      50 & 100 & 0,003 & 0,035 & 0,242 & \textbf{0,357} & 0,193 \\
      \hline
\end{tabular}
      \caption{NARM}
      \label{opt:NARM_rem}
\end{table}

\subsubsection{NextItNet}

As colunas de parâmetros são iterações, taxa de aprendizado e amostras
negativas, respectivamente. Resultados na tabela \ref{opt:NextItNet_rem}.
\begin{table}[htbp]
  \centering
  \begin{tabular}{|c|c|c|c|c|c|c|}
    \hline
      \multicolumn{3}{|c|}{Parâmetros} & \multicolumn{4}{c|}{Métricas @10} \\
      \hline
      it. & lr & a.n. & MAP & NDCG & Cov & Pop \\
      \hline
      30 & 0,0008 & True & \textbf{0,069} & \textbf{0,428} & 0,236 & 0,293 \\
      \hline
      20 & 0,008 & True & 0,043 & 0,243 & \textbf{0,282} & \textbf{0,287} \\
      \hline
\end{tabular}
      \caption{NextItNet}
      \label{opt:NextItNet_rem}
\end{table}

\subsubsection{skNN}
Parâmetros são quantidade de $k$ vizinhos, tamanho da amostra e função de
similaridade, respectivamente. Resultados na tabela \ref{opt:skNN_rem}.
\begin{table}[htbp]
  \centering
  \begin{tabular}{|c|c|c|c|c|c|c|}
    \hline
      \multicolumn{3}{|c|}{Parâmetros} & \multicolumn{4}{c|}{Métricas @10} \\
      \hline
      k & t.a. & sim. & MAP & NDCG & Cov & Pop \\
      \hline
      % sknn-k=500-sample_size=2500-similarity=jaccard	0.0895745066087272 0.40672235175568466	0.22857142857142856	0.2458629883636784
      500 & 2500 & Jaccard & \textbf{0,090} & 0,407 & 0,229 & 0,246 \\
      \hline
      % sknn-k=50-sample_size=5000-similarity=cosine	0.08360175629187037 0.3853441132352958	0.32491694352159467	0.19385074426789317
      50 & 5000 & Cosseno & 0,084 & 0,385 & \textbf{0,325} & \textbf{0,194} \\
      \hline
      \end{tabular}
      \caption{skNN}
      \label{opt:skNN_rem}
\end{table}

\subsubsection{smf}
Parâmetros são função objetivo, função de ativação final, \textit{dropout},
\textit{skip}, \textit{momentum} e taxa de aprendizado, respectivamente.
Resultados na tabela \ref{opt:smf_rem}.

\begin{table}[htbp]
  \centering
  \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|}
    \hline
      \multicolumn{6}{|c|}{Parâmetros} & \multicolumn{4}{c|}{Métricas @10} \\
      \hline
      f. obj. & f.at. & \textit{dropout} & \textit{skip} & \textit{momentum} & l.r. & MAP & NDCG & Cov & Pop \\
      \hline
      % smf-objective=top1_max-activation=linear-dropout=0.0-skip=0.4-momentum=0.6-learning_rate=0.01 0.08034311062828176 0.45417152416184275	0.22990033222591363	0.2601757887717391
      TOP1 & Linear & 0,0 & 0,4 & 0,6 & 0,01 & \textbf{0,080} & 0,454 & 0,230 & 0,260 \\
      \hline
      % smf-objective=bpr_max_org-activation=linear-dropout=0.1-skip=0.5-momentum=0.2-learning_rate=0.007	0.07934184320115877 0.4686334137765623	0.1707641196013289	0.28147958389613953
      BPR & Linear & 0,1 & 0,5 & 0,2 & 0,007 & 0,079 & \textbf{0,469} & 0,171 & 0,281 \\
      \hline
      \end{tabular}
      \caption{smf}
      \label{opt:smf_rem}
\end{table}

% sr
\subsubsection{Regras de sequência}
Parâmetros são número de passos e o peso, respectivamente. Resultados na tabela
\ref{opt:sr_rem}.

\begin{table}[htbp]
  \centering
  \begin{tabular}{|c|c|c|c|c|c|}
    \hline
      \multicolumn{2}{|c|}{Parâmetros} & \multicolumn{4}{c|}{Métricas @10} \\
      \hline
      passos & W & MAP & NDCG & Cov & Pop \\
      \hline
      % sr-steps=16-weighting=same	0.08512855332246966 0.46565806581280156	0.21926910299003322	0.28211189635801187
      16 & N/A, mesmo valor & \textbf{0,085} & \textbf{0,466} & 0,219 & 0,282 \\
      \hline
      % sr-steps=6-weighting=quadratic	0.07527068622125656 0.4437347725789425	0.24053156146179402	0.2627917742578618
      6 & Quadrático & 0,075 & 0,444 & \textbf{0,241} & \textbf{0,263} \\
      \hline
\end{tabular}
      \caption{Regras de sequência}
      \label{opt:sr_rem}
\end{table}

\subsubsection{STAMP}
Parâmetros são número de épocas, taxa de decaimento e taxa de aprendizado inicial, respectivamente.
Resultados na tabela \ref{opt:stamp_rem}.

\begin{table}[htbp]
  \centering
  \begin{tabular}{|c|c|c|c|c|c|c|}
    \hline
      \multicolumn{3}{|c|}{Parâmetros} & \multicolumn{4}{c|}{Métricas @10} \\
      \hline
      epochs & taxa de decaimento & l.r. inicial & MAP & NDCG & Cov & Pop \\
      \hline
      10 & 0,2 & 0,006 & \textbf{0,084} & 0,496 & 0,297 & 0,238 \\
      \hline
      % stamp-n_epochs=20-decay_rate=0.8-init_lr=0.004	0.07872397247872528 0.5049868858123603	0.33488372093023255	0.2248663180579398
      20 & 0,8 & 0,004 & 0,079 & \textbf{0,505} & 0,335 & \textbf{0,225} \\
      \hline
      % stamp-n_epochs=30-decay_rate=0.3-init_lr=0.009	0.0711429476733659 0.42828497342242244	0.39069767441860465	0.23079262854994154
      30 & 0,3 & 0,009 & 0,071 & 0,428 & \textbf{0,391} & 0,231 \\
      \hline
\end{tabular}
      \caption{STAMP}
      \label{opt:stamp_rem}
\end{table}

% vsknn
\subsubsection{vsKNN}
Parâmetros sao a quantidade de vizinhos $k$, tamanho da amostra, peso e peso na
pontuação e peso idf.


\begin{table}[htbp]
  \centering
  \begin{tabular}{|c|c|c|c|c|c|c|c|c|}
    \hline
      \multicolumn{5}{|c|}{Parâmetros} & \multicolumn{4}{c|}{Métricas @10} \\
      \hline
      k & t.a. & W & $W_{\textbf{score}}$ & $W_{\textbf{idf}}$ & MAP & NDCG & Cov & Pop \\
      \hline
      % vsknn-k=100-sample_size=500-weighting=same-weighting_score=quadratic-idf_weighting=False	0.0898551511859497 0.41207888552936317	0.23056478405315614	0.24516626318785026
      100 & 500 & N/A & Quadrático & False & \textbf{0,090} & \textbf{0,412} & 0,231 & \textbf{0,245} \\
      \hline
      % vsknn-k=50-sample_size=2500-weighting=log-weighting_score=log-idf_weighting=10	0.08605784899511137 0.3893277949089159	0.30033222591362124	0.18338254222327224
      50 & 2500 & Log & Log & 10 & 0,086 & 0,389 & \textbf{0,300} & 0,183 \\
      \hline
\end{tabular}
      \caption{vsKNN}
      \label{opt:vsknn_rem}
\end{table}

\begin{table}[htbp]
  \centering
  \begin{tabular}{|c|c|c|c|c|c|c|c|c|}
    \hline
      \multicolumn{5}{|c|}{Parâmetros} & \multicolumn{4}{c|}{Métricas @10} \\
      \hline
      k & t.a. & $\lambda_{\text{spw}}$ & $\lambda_{\text{snh}}$ & $\lambda_{\text{inh}}$ & MAP & NDCG & Cov & Pop \\
      \hline
      % stan-k=500-sample_size=1000-lambda_spw=7.24-lambda_snh=20-lambda_inh=3.62	0.08788430200977725 0.3981468203881023	0.21993355481727575	0.2417896510239575
      500 & 1000 & 7,24 & 20 & 3,62 & \textbf{0,088} & 0,398 & \textbf{0,220} & \textbf{0,242} \\
      \hline
      % stan-k=1500-sample_size=2500-lambda_spw=1.81-lambda_snh=40-lambda_inh=3.62	0.08684636972659784 0.4041810177346703	0.21926910299003322	0.2626352865797759
      1500 & 2500 & 1,81 & 40 & 3,62 & 0,087 & \textbf{0,404} & 0,219 & 0,263 \\
      \hline 
\end{tabular}
      \caption{STAN}
      \label{opt:stan_rem}
\end{table}

\begin{table}[htbp]
  \centering
  \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|}
    \hline
      \multicolumn{8}{|c|}{Parâmetros} & \multicolumn{4}{c|}{Métricas @10} \\
      \hline
      k & t.a. & sim & $\lambda_{\text{spw}}$ & $\lambda_{\text{snh}}$ & $\lambda_{\text{inh}}$ & $\lambda_{\text{ipw}}$ & $\lambda_{\text{IDF}}$ & MAP & NDCG & Cov & Pop \\
      \hline
      % vstan-k=1500-sample_size=10000-similarity=cosine-lambda_spw=1.81-lambda_snh=80-lambda_inh=7.24-lambda_ipw=3.62-lambda_idf=False	0.08434048524352708 0.4080046765728457	0.21661129568106313	0.2684444159175518
      1500 & 10000 & Cosseno & 1,81 & 80 & 7,24 & 3,62 & False & \textbf{0,084} & \textbf{0,408} & 0,217 & 0,268 \\
      \hline
      % vstan-k=100-sample_size=2500-similarity=vec-lambda_spw=3.62-lambda_snh=80-lambda_inh=0.905-lambda_ipw=0.905-lambda_idf=10	0.07795627376425854 0.3555359734993043	0.3229235880398671	0.15615397024291666
      100 & 2500 & Vetorial & 3,62 & 80 & 0,905 & 0,905 & 10 & 0,078 & 0,356 & \textbf{0,323} & \textbf{0,156} \\
      \hline
\end{tabular}
      \caption{VSTAN}
      \label{opt:vstan_rem}
\end{table}

\begin{table}[htbp]
  \centering
  \begin{tabular}{|c|c|c|c|c|c|c|c|}
    \hline
      \multicolumn{4}{|c|}{Parâmetros} & \multicolumn{4}{c|}{Métricas @10} \\
      \hline
      un. ocultas & epochs & l.r. & m.s. & MAP & NDCG & Cov & Pop \\
      \hline
      % csrm-hidden_units=100-epoch=10-lr=0.0009-memory_size=256	0.036032953105196476
      100 & 10 & 0,0009 & 256 & \textbf{0,036} & \textbf{0,256} & 0,300 & 0,210 \\
      \hline
      % csrm-hidden_units=100-epoch=10-lr=0.0007-memory_size=128	0.03471845011768966
      100 & 10 & 0,0007 & 128 & 0,035 & 0,247 & \textbf{0,301} & \textbf{0,211} \\
      \hline
     \end{tabular}
      \caption{CSRM}
      \label{opt:csrm_rem}
\end{table}


\newpage

\section{\textit{session-based}, \textit{last item}}

\begin{table}[htbp]
  \centering
  \begin{tabular}{|c|c|c|c|c|c|c|c|c|}
      \hline
      GNN & GRU4Rec & NARM & NextItNet & STAMP & SMF & sr & sKNN & vsKNN \\
      \hline
      2h05 & 2h47 & 9h01 & 1h37 & 0h28 &  3h21 & 0h01 & 0h01 & 0h01 \\
      \hline
      \end{tabular}
      \caption{Duração da otimização, em horas e minutos para cada modelo.}
\end{table}

A seguir, otimizações para os modelos \textit{session-based} com abordagem \textit{last
item}. Os parâmetros fixos são os mesmos para a otimização na abordagem \textit{remaining items}.

\begin{table}[htbp]
  \centering
  \begin{tabular}{|c|c|c|c|c|c|c|c|}
    \hline
      \multicolumn{4}{|c|}{Parâmetros} & \multicolumn{4}{c|}{Métricas @10} \\
      \hline
      lr & l2 & $\text{lr}_\text{dc}$ & $\text{lr}_\text{dc}$ & MRR & HR & Cov & Pop \\
      \hline
      % lr=0.005-l2=6e-06-lr_dc=0.7222222-lr_dc_step=7	0.4785317460317461 0,685 0.2830564784053156	0.1903069913355243
      0,005 & $6 \times 10^{-6}$ & 0,722 & 7 & \textbf{0,479} & \textbf{0,685} & 0,283 & \textbf{0,190} \\
      \hline
      % sgnn-hidden_size=100-lr=0.009-l2=5e-06-lr_dc=0.45555556-lr_dc_step=3	0.4133015873015872 0.63 0.2950166112956811	0.19517463400059756
      0,009 & $5 \times 10^{-6}$ & 0,455 & 3 & 0,413 & 0,630 & \textbf{0,295} & 0,195 \\
      \hline
\end{tabular}
      \caption{GNN}
      \label{opt:GNN_last}
\end{table}

\begin{table}[htbp]
  \centering
  \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|}
    \hline
      \multicolumn{6}{|c|}{Parâmetros} & \multicolumn{4}{c|}{Métricas @10} \\
      \hline
      custo & final & \textit{dropout} & \textit{momentum} & c.e. & l.r. & MRR & HR & Cov & Pop \\
      \hline
      % gru4rec-los-momentum=0.0-learning_rate=0.1-constrained_embedding=True	0.18695833333333337 0,285 0.4299003322259136	0.04305736480430239
      TOP1 & Linear & 0,3 & 0,0 & True & 0,1 & \textbf{0,187} & \textbf{0,285} & 0,430 & 0,043 \\
      \hline
      % gru4rec-loss=.0-momentum=0.1-learning_rate=0.2-constrained_embedding=False	0.1848809523809524 0.3 0.44518272425249167	0.03536316103973709
      TOP1 & ELU & 0,0 & 0,1 & False & 0,2 & 0,185 & 0,300 & \textbf{0,445} & \textbf{0,035} \\
      \hline
\end{tabular}
      \caption{GRU4Rec}
      \label{opt:GRU4Rec_last}
\end{table}

\begin{table}[htbp]
  \centering
  \begin{tabular}{|c|c|c|c|c|c|c|}
    \hline
      \multicolumn{3}{|c|}{Parâmetros} & \multicolumn{4}{c|}{Métricas @10} \\
      \hline
      fatores & unidades ocultas & lr & MRR & HR & Cov & Pop \\
      \hline
      % narm-epochs=20-factors=100-hidden_units=100-lr=0.003	0.24491468253968257 0.43 0.26112956810631227	0.2063361219002092
      100 & 100 & 0,003 & \textbf{0,245} & 0,430 & 0,261 & 0,206 \\
      \hline
      % narm-epochs=20-factors=50-hidden_units=100-lr=0.008 0.19784126984126996 0,455 0.28039867109634553	0.1850649835673739
      50 & 100 & 0,008 & 0,198 & \textbf{0,455} & \textbf{0,280} & \textbf{0,185} \\
      \hline
\end{tabular}
      \caption{NARM}
      \label{opt:NARM_last}
\end{table}

\begin{table}[htbp]
  \centering
  \begin{tabular}{|c|c|c|c|c|c|c|}
    \hline
      \multicolumn{3}{|c|}{Parâmetros} & \multicolumn{4}{c|}{Métricas @10} \\
      \hline
      epochs & taxa de decaimento & l.r. inicial & MRR & HR & Cov & Pop \\
      \hline
      20 & 0,8 & 0,005 & \textbf{0,429} & \textbf{0,565} & 0,234 & 0,236 \\
      \hline
      20 & 0,7 & 0,009 & 0,404 & 0,505 & \textbf{0,303} & \textbf{0,181} \\
      \hline
\end{tabular}
      \caption{STAMP}
      \label{opt:stamp_last}
\end{table}

\begin{table}[htbp]
  \centering
  \begin{tabular}{|c|c|c|c|c|c|c|}
    \hline
      \multicolumn{3}{|c|}{Parâmetros} & \multicolumn{4}{c|}{Métricas @10} \\
      \hline
      it. & lr & a.n. & MRR & HR & Cov & Pop \\
      \hline
      % nextitnet-learning_rate=0.0006-iterations=30-is_negsample=True	0.31365476190476205 0,555  0.19269102990033224	0.2601680609501046
      30 & 0,0006 & True & \textbf{0,314} & 0,555 & 0,193 & 0,260 \\
      \hline
      % nextitnet-learning_rate=0.001-iterations=30-is_negsample=True	0.30495833333333355  0.61 0.30495833333333355	0.1920265780730897
      30 & 0,001 & True & 0,305 & \textbf{0,610} & \textbf{0,305} & \textbf{0,192} \\
      \hline
      % nextitnet-learning_rate=0.005-iterations=30-is_negsample=True	0.23621230158730167 0.51 0.2345514950166113	0.24483746638780982
      30 & 0,005 & True & 0,236 & 0,510 & 0,235 & 0,245 \\
      \hline
\end{tabular}
      \caption{NextItNet}
      \label{opt:NextItNet_last}
\end{table}

\begin{table}[htbp]
  \centering
  \begin{tabular}{|c|c|c|c|c|c|c|}
    \hline
      \multicolumn{3}{|c|}{Parâmetros} & \multicolumn{4}{c|}{Métricas @10} \\
      \hline
      k & t.a. & sim. & MRR & HR & Cov & Pop \\
      \hline
      % sknn-k=100-sample_size=10000-similarity=jaccard	0.2631944444444449 0.72 0.2425249169435216	0.19841484911861357
      100 & 10000 & Jaccard & \textbf{0,263} & \textbf{0,720} & 0,243 & 0,198 \\
      \hline
      % sknn-k=50-sample_size=1000-similarity=jaccard	0.25625793650793677 0.7 0.2757475083056478	0.1740848521063639
      50 & 1000 & Jaccard & 0,256 & 0,700 & \textbf{0,276} & \textbf{0,174} \\
      \hline
\end{tabular}
      \caption{skNN}
      \label{opt:skNN_last}
\end{table}

\begin{table}[htbp]
  \centering
  \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|}
    \hline
      \multicolumn{6}{|c|}{Parâmetros} & \multicolumn{4}{c|}{Métricas @10} \\
      \hline
      f. obj. & f.at. & \textit{dropout} & \textit{skip} & \textit{momentum} & l.r. & MRR & HR & Cov & Pop \\
      \hline
      % smf-objective=top1_max-activation=linear-dropout=0.4-skip=0.4-momentum=0.1-learning_rate=0.01	0.34961507936507963 0,605 0.13488372093023257	0.2683171496862862
      TOP1 & Linear & 0,4 & 0,4 & 0,1 & 0,01 & \textbf{0,350} & 0,605 & \textbf{0,135} & \textbf{0,268} \\
      \hline
      % smf-objective=bpr_max_org-activation=linear-dropout=0.4-skip=0.0-momentum=0.0-learning_rate=0.07	0.30415674603174625 0.660 0.24584717607973422	0.21433955781296693
      BPR & Linear & 0,4 & 0,0 & 0,0 & 0,07 & 0,304 & \textbf{0,660} & 0,246 & 0,214 \\
      \hline
      % smf-objective=bpr_max_org-activation=linear-dropout=0.4-skip=0.3-momentum=0.3-learning_rate=0.3	0.2022301587301588 0.39 0.30033222591362124	0.16397281147296072
      BPR & Linear & 0,4 & 0,3 & 0,3 & 0,3 & 0,202 & 0,390 & \textbf{0,300} & 0,164 \\
      \hline
\end{tabular}
      \caption{smf}
      \label{opt:smf_last}
\end{table}

\begin{table}[htbp]
  \centering
  \begin{tabular}{|c|c|c|c|c|c|}
    \hline
      \multicolumn{2}{|c|}{Parâmetros} & \multicolumn{4}{c|}{Métricas @10} \\
      \hline
      passos & W & MRR & HR & Cov & Pop \\
      \hline
      % sr-steps=17-weighting=same	0.33194047619047645 0.64 0.16677740863787374	0.2628026590976996
      17 & N/A & \textbf{0,331} & 0,640 & 0,167 & 0,262 \\
      \hline
% sr-steps=15-weighting=quadratic	0.32178968253968276 0,635 0.18272425249169436	0.24295921720944133
      15 & Quadrático & 0,322 & 0,635 & \textbf{0,182} & \textbf{0,243} \\
      \hline
% sr-steps=20-weighting=div	0.3198234126984129 0,65 0,171 0,253
      20 & div & 0,320 & \textbf{0,650} & 0,171 & 0,253 \\
      \hline

\end{tabular}
      \caption{Regras de sequência}
      \label{opt:sr_last}
\end{table}

\begin{table}[htbp]
  \centering
  \begin{tabular}{|c|c|c|c|c|c|c|c|c|}
    \hline
      \multicolumn{5}{|c|}{Parâmetros} & \multicolumn{4}{c|}{Métricas @10} \\
      \hline
      k & t.a. & W & $W_{\textbf{score}}$ & $W_{\textbf{idf}}$ & MRR & HR & Cov & Pop \\
      \hline
      % vsknn-k=50-sample_size=2500-weighting=log-weighting_score=same-idf_weighting=False	0.24739880952380972 0.68 0.20730897009966778	0.21379533910965054
      50 & 2500 & Log & N/A & False & \textbf{0,247} & \textbf{0,680} & 0,207 & 0,214\\
      \hline
      % vsknn-k=50-sample_sizeg=same-weighting_score0.228023835 0.68 0.24651162790697675	0.16500239020017912
      50 & 5000 & N/A & Quadrático & 10 & 0,228 & \textbf{0,680} & \textbf{0,246} & \textbf{0,165}\\
      \hline
\end{tabular}
      \caption{vsKNN}
      \label{opt:vsknn_last}
\end{table}

\begin{table}[htbp]
  \centering
  \begin{tabular}{|c|c|c|c|c|c|c|c|c|}
    \hline
      \multicolumn{5}{|c|}{Parâmetros} & \multicolumn{4}{c|}{Métricas @10} \\
      \hline
      k & t.a. & $\lambda_{\text{spw}}$ & $\lambda_{\text{snh}}$ & $\lambda_{\text{inh}}$ & MRR & HR & Cov & Pop \\
      \hline
      % stan-k=100-sample_size=10000-lambda_spw=3.62-lambda_snh=80-lambda_inh=7.24	0.1949330274745558 0.5488372093023256 0.1949330274745558	0.5302325581395348
      100 & 10000 & 3,62 & 80 & 7,24 & \textbf{0,195} & 0,549 & 0,530 & \textbf{0,189}  \\
      \hline
      % stan-k=100-sample_size=10000-lambda_spw=7.24-lambda_snh=80-lambda_inh=0.905	0.18852976849654562 0.5558139534883721 0.5475083056478405	0.1907618564549799
      100 & 10000 & 7,24 & 80 & 0,905 & 0,189 & \textbf{0,556} & \textbf{0,548} & 0,191 \\
      \hline
\end{tabular}
      \caption{stan}
      \label{opt:stan_last}
\end{table}

\begin{table}[htbp]
  \centering
  \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|}
    \hline
      \multicolumn{8}{|c|}{Parâmetros} & \multicolumn{4}{c|}{Métricas @10} \\
      \hline
      k & t.a. & sim & $\lambda_{\text{spw}}$ & $\lambda_{\text{snh}}$ & $\lambda_{\text{inh}}$ & $\lambda_{\text{ipw}}$ & $\lambda_{\text{IDF}}$ & MRR & HR & Cov & Pop \\
      \hline
      % vstan-k=1000-sample_size=2500-similarity=vec-lambda_spw=7.24-lambda_snh=40-lambda_inh=1.81-lambda_ipw=0.905-lambda_idf=False	0.18798172757475112 0.5325581395348837 0.5156146179401994	0.24296693523331747
      1000 & 2500 & vec & 7,24 & 40 & 1,81 & 0,905 & False & \textbf{0,188} & \textbf{0,533} & 0,516 & 0,243 \\
      \hline
      % vstan-k=100-sample_size=5000-similarity=cosine-lambda_spw=1.81-lambda_snh=100-lambda_inh=7.24-lambda_ipw=0.905-lambda_idf=1	0.1771929547012607 0.501328903654485 0.5833887043189369	0.1506057092829696
      100 & 5000 & cosseno & 1,81 & 100 & 7,24 & 0,905 & 1 & 0,177 & 0,501 & \textbf{0,583} & \textbf{0,151} \\
      \hline
\end{tabular}
      \caption{vstan}
      \label{opt:vstan_last}
\end{table}


\begin{table}[htbp]
  \centering
  \begin{tabular}{|c|c|c|c|c|c|c|c|}
    \hline
      \multicolumn{4}{|c|}{Parâmetros} & \multicolumn{4}{c|}{Métricas @10} \\
      \hline
      un. ocultas & \textit{epochs} & l.r. & m.s. & MRR & HR & Cov & Pop \\
      \hline
      % csrm-hidden_units=100-epoch=10-lr=0.0009-memory_size=256	0.21431547619047617 0,395 0,281 0,143
      100 & 10 & 0,0009 & 256 & \textbf{0,214} & \textbf{0,395} & \textbf{0,281} & \textbf{0,143} \\
      \hline
      100 & 10 & 0,001 & 256 & 0,175 & 0,405 & 0,274 & 0,134 \\
      \hline


\end{tabular}
      \caption{CSRM}
      \label{opt:csrm_last}
\end{table}